{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dis-AE 2: Basic Usage\n",
    "\n",
    "This notebook demonstrates the basic API usage of Dis-AE 2 (Domain Separation Network Multi-Domain Adversarial Autoencoder) with synthetic data.\n",
    "\n",
    "## What is Dis-AE 2?\n",
    "\n",
    "Dis-AE 2 is a **domain-invariant learning** model that:\n",
    "- Separates features into **shared** (domain-invariant, task-relevant) and **private** (domain-specific, for reconstruction)\n",
    "- Uses **adversarial training** to prevent domain information from leaking into shared features\n",
    "- Supports **multiple tasks** and **multiple domain factors** simultaneously\n",
    "- Provides a **scikit-learn-style API** for easy integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "from sysmexcbctools.disae2.disae2 import DisAE\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# PDF-compatible fonts\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "\n",
    "# Scientific plot style\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use([\"science\", \"nature\"])\n",
    "\n",
    "# Colourblind-friendly palette\n",
    "SEABORN_PALETTE = \"colorblind\"\n",
    "seaborn_colors = sns.color_palette(SEABORN_PALETTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Data\n",
    "\n",
    "We'll create a nonsensical synthetic dataset with:\n",
    "- **1000 samples** with **32 features**\n",
    "- **2 tasks**: binary classification and 3-class classification\n",
    "- **3 domain factors**: machine (5 levels), time (10 levels), delay (10 levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Data dimensions\n",
    "n_samples = 1000\n",
    "n_features = 32\n",
    "\n",
    "# Generate Task 1: Binary classification\n",
    "X_task1, y_task_1 = make_classification(\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_features,\n",
    "    n_informative=10,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=2,\n",
    "    flip_y=0.1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Generate Task 2: 3-class classification\n",
    "X_task2, y_task_2 = make_classification(\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_features,\n",
    "    n_informative=8,\n",
    "    n_redundant=4,\n",
    "    n_classes=3,\n",
    "    n_clusters_per_class=1,\n",
    "    flip_y=0.1,\n",
    "    random_state=43,\n",
    ")\n",
    "\n",
    "# Combine tasks: weighted average of features (shared information)\n",
    "X = 0.6 * X_task1 + 0.4 * X_task2\n",
    "\n",
    "# Stack the two classification tasks\n",
    "y_tasks = np.column_stack([y_task_1, y_task_2])\n",
    "\n",
    "# Three domain factors\n",
    "y_domain_1 = np.random.randint(0, 5, size=n_samples)  # 5 machines\n",
    "y_domain_2 = np.random.randint(0, 10, size=n_samples)  # 10 time bins\n",
    "y_domain_3 = np.random.randint(0, 10, size=n_samples)  # 10 delay bins\n",
    "y_domains = np.column_stack([y_domain_1, y_domain_2, y_domain_3])\n",
    "\n",
    "# Add domain influences to features\n",
    "# Domain 1 (machine): systematic shift on first 10 features\n",
    "for machine_id in range(5):\n",
    "    mask = y_domain_1 == machine_id\n",
    "    X[mask, :10] += np.random.randn(10) * 0.5 * machine_id\n",
    "\n",
    "# Domain 2 (time): linear drift on features 10-20\n",
    "for time_bin in range(10):\n",
    "    mask = y_domain_2 == time_bin\n",
    "    X[mask, 10:20] += np.linspace(0, 1, 10) * time_bin * 0.1\n",
    "\n",
    "# Domain 3 (delay): random noise on features 20-30\n",
    "for delay_bin in range(10):\n",
    "    mask = y_domain_3 == delay_bin\n",
    "    X[mask, 20:30] += np.random.randn(np.sum(mask), 10) * 0.3 * delay_bin / 10\n",
    "\n",
    "# Split into train and validation\n",
    "train_size = int(0.8 * n_samples)\n",
    "X_train = X[:train_size]\n",
    "y_tasks_train = y_tasks[:train_size]\n",
    "y_domains_train = y_domains[:train_size]\n",
    "\n",
    "X_val = X[train_size:]\n",
    "y_tasks_val = y_tasks[train_size:]\n",
    "y_domains_val = y_domains[train_size:]\n",
    "\n",
    "print(\"Dataset Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Validation samples: {X_val.shape[0]}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"\\nTasks: {y_tasks_train.shape[1]}\")\n",
    "print(f\"  Task 1: {len(np.unique(y_tasks_train[:, 0]))} classes (binary)\")\n",
    "print(f\"  Task 2: {len(np.unique(y_tasks_train[:, 1]))} classes (3-class)\")\n",
    "print(f\"\\nDomain factors: {y_domains_train.shape[1]}\")\n",
    "print(f\"  Domain 1 (machine): {len(np.unique(y_domains_train[:, 0]))} levels\")\n",
    "print(f\"  Domain 2 (time): {len(np.unique(y_domains_train[:, 1]))} levels\")\n",
    "print(f\"  Domain 3 (delay): {len(np.unique(y_domains_train[:, 2]))} levels\")\n",
    "print(f\"\\nDomain influences:\")\n",
    "print(f\"  Machine: systematic shift on features 0-9\")\n",
    "print(f\"  Time: linear drift on features 10-19\")\n",
    "print(f\"  Delay: random noise on features 20-29\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Dis-AE 2 Model\n",
    "\n",
    "Key hyperparameters:\n",
    "- `input_dim`: Number of input features\n",
    "- `latent_dim`: Total latent dimension (split into shared + private)\n",
    "- `num_tasks`: List of number of classes per task\n",
    "- `num_domains`: List of cardinalities per domain factor\n",
    "- `reconstruction_weight`: Weight for reconstruction loss (helps preserve information)\n",
    "- `adversarial_weight`: Weight for adversarial domain loss (controls domain invariance)\n",
    "- `orthogonality_weight`: Weight for orthogonality loss (separates shared/private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = DisAE(\n",
    "    input_dim=n_features,\n",
    "    latent_dim=16,  # Total latent dimension\n",
    "    num_tasks=[2, 3],  # Binary and 3-class tasks\n",
    "    num_domains=[5, 10, 10],  # Three domain factors\n",
    "    hidden_dims=[64, 32],  # Hidden layer dimensions\n",
    "    reconstruction_weight=0.1,\n",
    "    adversarial_weight=1.0,\n",
    "    orthogonality_weight=0.1,\n",
    "    learning_rate=0.01,\n",
    "    batch_size=128,\n",
    "    device=\"cpu\",  # Use 'cuda' if GPU available\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Input dimension: {model.input_dim}\")\n",
    "print(f\"Latent dimension: {model.latent_dim}\")\n",
    "print(f\"  - Shared (domain-invariant): {model.shared_dim}\")\n",
    "print(f\"  - Private (domain-specific): {model.private_dim}\")\n",
    "print(f\"Tasks: {model.num_tasks}\")\n",
    "print(f\"Domain factors: {model.num_domains}\")\n",
    "print(f\"Hidden layers: {model.hidden_dims}\")\n",
    "print(f\"\\nLoss weights:\")\n",
    "print(f\"  - Reconstruction: {model.reconstruction_weight}\")\n",
    "print(f\"  - Adversarial: {model.adversarial_weight}\")\n",
    "print(f\"  - Orthogonality: {model.orthogonality_weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model\n",
    "\n",
    "The model uses:\n",
    "- **Adversarial training**: Alternates between updating discriminators and generator\n",
    "- **Early stopping**: Monitors validation loss to prevent overfitting\n",
    "- **Multiple objectives**: Task classification + reconstruction + adversarial + orthogonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Training Dis-AE 2...\\n\")\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_tasks_train,\n",
    "    y_domains_train,\n",
    "    X_val=X_val,\n",
    "    y_tasks_val=y_tasks_val,\n",
    "    y_domains_val=y_domains_val,\n",
    "    max_epochs=100,\n",
    "    early_stopping_patience=16,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Task Predictions\n",
    "\n",
    "The model uses only **shared features** for task prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task predictions\n",
    "y_pred = model.predict_tasks(X_val)\n",
    "y_proba = model.predict_tasks_proba(X_val)\n",
    "\n",
    "print(\"Task Prediction Results:\")\n",
    "print(\"=\" * 50)\n",
    "for i, (preds, proba) in enumerate(zip(y_pred, y_proba)):\n",
    "    accuracy = (preds == y_tasks_val[:, i]).mean()\n",
    "    confidence = proba.max(axis=1).mean()\n",
    "    print(f\"\\nTask {i + 1}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Mean confidence: {confidence:.4f}\")\n",
    "    print(f\"  Predictions shape: {preds.shape}\")\n",
    "    print(f\"  Probabilities shape: {proba.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Domain Predictions (Domain Invariance Check)\n",
    "\n",
    "**Important**: For good domain generalisation, domain prediction accuracy should be **low** (close to random chance).\n",
    "\n",
    "This indicates that shared features don't contain domain-specific information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain predictions\n",
    "d_pred = model.predict_domains(X_val)\n",
    "d_proba = model.predict_domains_proba(X_val)\n",
    "\n",
    "print(\"Domain Prediction Results (Lower is Better):\")\n",
    "print(\"=\" * 50)\n",
    "for i, (preds, proba) in enumerate(zip(d_pred, d_proba)):\n",
    "    accuracy = (preds == y_domains_val[:, i]).mean()\n",
    "    random_chance = 1.0 / model.num_domains[i]\n",
    "    print(f\"\\nDomain Factor {i + 1}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Random chance: {random_chance:.4f}\")\n",
    "    if accuracy <= random_chance * 1.2:  # Within 20% of random\n",
    "        print(f\"  ✓ Good domain invariance!\")\n",
    "    else:\n",
    "        print(f\"  ⚠ Domain information may be leaking into shared features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Embeddings\n",
    "\n",
    "Extract **shared** and **private** features to analyze feature separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "shared, private = model.embed(X_val, private=True)\n",
    "shared_only = model.embed(X_val, private=False)\n",
    "\n",
    "print(\"Embedding Dimensions:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shared features: {shared.shape}\")\n",
    "print(f\"Private features: {private.shape}\")\n",
    "print(f\"\\nFeature Statistics:\")\n",
    "print(f\"Shared - mean: {shared.mean():.4f}, std: {shared.std():.4f}\")\n",
    "print(f\"Private - mean: {private.mean():.4f}, std: {private.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Feature Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlations\n",
    "shared_corr = np.corrcoef(shared.T)\n",
    "private_corr = np.corrcoef(private.T)\n",
    "shared_private_corr = np.corrcoef(np.concatenate([shared, private], axis=1).T)[\n",
    "    : shared.shape[1], shared.shape[1] :\n",
    "]\n",
    "\n",
    "# Plot correlations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(6.6, 2.2))\n",
    "\n",
    "im1 = axes[0].imshow(shared_corr, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "axes[0].set_title(\"Shared-Shared Correlation\")\n",
    "axes[0].set_xlabel(\"Shared Feature\")\n",
    "axes[0].set_ylabel(\"Shared Feature\")\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "im2 = axes[1].imshow(private_corr, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "axes[1].set_title(\"Private-Private Correlation\")\n",
    "axes[1].set_xlabel(\"Private Feature\")\n",
    "axes[1].set_ylabel(\"Private Feature\")\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "im3 = axes[2].imshow(shared_private_corr, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "axes[2].set_title(\"Shared-Private Correlation\\n(Should be low)\")\n",
    "axes[2].set_xlabel(\"Private Feature\")\n",
    "axes[2].set_ylabel(\"Shared Feature\")\n",
    "plt.colorbar(im3, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean absolute correlation:\")\n",
    "print(f\"  Shared-Shared: {np.abs(shared_corr).mean():.4f}\")\n",
    "print(f\"  Private-Private: {np.abs(private_corr).mean():.4f}\")\n",
    "print(f\"  Shared-Private: {np.abs(shared_private_corr).mean():.4f}\")\n",
    "print(f\"\\n✓ Lower Shared-Private correlation indicates better feature separation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Embeddings with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA projection\n",
    "pca_shared = PCA(n_components=2).fit_transform(shared)\n",
    "pca_private = PCA(n_components=2).fit_transform(private)\n",
    "\n",
    "with plt.style.context([\"science\", \"nature\", \"scatter\"]):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(4.5, 2.2))\n",
    "\n",
    "    # Shared features coloured by task\n",
    "    scatter1 = axes[0].scatter(\n",
    "        pca_shared[:, 0],\n",
    "        pca_shared[:, 1],\n",
    "        c=y_tasks_val[:, 0],\n",
    "        cmap=\"viridis\",\n",
    "        s=5,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    axes[0].set_title(\"Shared Features (coloured by Task 1)\")\n",
    "    axes[0].set_xlabel(\"PC1\")\n",
    "    axes[0].set_ylabel(\"PC2\")\n",
    "    plt.colorbar(scatter1, ax=axes[0], label=\"Task Label\")\n",
    "\n",
    "    # Private features coloured by domain\n",
    "    scatter2 = axes[1].scatter(\n",
    "        pca_private[:, 0],\n",
    "        pca_private[:, 1],\n",
    "        c=y_domains_val[:, 0],\n",
    "        cmap=\"plasma\",\n",
    "        s=5,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    axes[1].set_title(\"Private Features (coloured by Domain 1)\")\n",
    "    axes[1].set_xlabel(\"PC1\")\n",
    "    axes[1].set_ylabel(\"PC2\")\n",
    "    plt.colorbar(scatter2, ax=axes[1], label=\"Domain Label\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reconstruction\n",
    "\n",
    "The model reconstructs inputs using **both** shared and private features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct data\n",
    "X_reconstructed = model.reconstruct(X_val)\n",
    "reconstruction_mse = np.mean((X_val - X_reconstructed) ** 2)\n",
    "\n",
    "print(\"Reconstruction Quality:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE: {reconstruction_mse:.6f}\")\n",
    "print(f\"\\nPer-feature MSE statistics:\")\n",
    "per_feature_mse = np.mean((X_val - X_reconstructed) ** 2, axis=0)\n",
    "print(f\"  Mean: {per_feature_mse.mean():.6f}\")\n",
    "print(f\"  Std: {per_feature_mse.std():.6f}\")\n",
    "print(f\"  Min: {per_feature_mse.min():.6f}\")\n",
    "print(f\"  Max: {per_feature_mse.max():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstruction\n",
    "fig, axes = plt.subplots(1, 2, figsize=(4.5, 2.2))\n",
    "\n",
    "# Original vs reconstructed for first 5 samples\n",
    "n_samples_to_plot = 5\n",
    "x_pos = np.arange(n_features)\n",
    "for i in range(n_samples_to_plot):\n",
    "    axes[0].plot(\n",
    "        x_pos, X_val[i], alpha=0.3, label=f\"Original {i + 1}\" if i == 0 else None\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        x_pos,\n",
    "        X_reconstructed[i],\n",
    "        alpha=0.3,\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Reconstructed {i + 1}\" if i == 0 else None,\n",
    "    )\n",
    "axes[0].set_title(\"Original vs Reconstructed (First 5 Samples)\")\n",
    "axes[0].set_xlabel(\"Feature Index\")\n",
    "axes[0].set_ylabel(\"Feature Value\")\n",
    "axes[0].legend([\"Original\", \"Reconstructed\"])\n",
    "\n",
    "# Reconstruction error distribution\n",
    "reconstruction_errors = np.sqrt(np.sum((X_val - X_reconstructed) ** 2, axis=1))\n",
    "axes[1].hist(reconstruction_errors, bins=30, edgecolor=\"black\", alpha=0.7)\n",
    "axes[1].set_title(\"Reconstruction Error Distribution\")\n",
    "axes[1].set_xlabel(\"L2 Error\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "axes[1].axvline(\n",
    "    reconstruction_errors.mean(),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean: {reconstruction_errors.mean():.3f}\",\n",
    ")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Persistence\n",
    "\n",
    "Save and load the trained model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = \"disae2_basic_example.pkl\"\n",
    "model.save(model_path)\n",
    "print(f\"✓ Model saved to {model_path}\")\n",
    "\n",
    "# Load model\n",
    "loaded_model = DisAE.load(model_path)\n",
    "print(f\"✓ Model loaded successfully\")\n",
    "\n",
    "# Verify loaded model\n",
    "y_pred_loaded = loaded_model.predict_tasks(X_val)\n",
    "for i in range(len(y_pred)):\n",
    "    assert np.array_equal(\n",
    "        y_pred[i], y_pred_loaded[i]\n",
    "    ), f\"Task {i} predictions don't match!\"\n",
    "print(f\"✓ Loaded model produces identical predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✓ **Data preparation**: Multi-task, multi-domain dataset\n",
    "2. ✓ **Model initialization**: Configuring Dis-AE 2 hyperparameters\n",
    "3. ✓ **Training**: Adversarial training with early stopping\n",
    "4. ✓ **Task prediction**: Using domain-invariant shared features\n",
    "5. ✓ **Domain invariance**: Verifying low domain prediction accuracy\n",
    "6. ✓ **Feature embeddings**: Analyzing shared vs private features\n",
    "7. ✓ **Reconstruction**: Quality assessment\n",
    "8. ✓ **Model persistence**: Save/load functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bloodcounts_sysmex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
