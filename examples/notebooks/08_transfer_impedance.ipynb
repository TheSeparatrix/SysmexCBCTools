{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impedance Data Alignment with ImpedanceTransformer\n",
    "\n",
    "This notebook demonstrates how to align Sysmex impedance data (RBC and PLT histograms) between different analysers using the `ImpedanceTransformer` API.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `ImpedanceTransformer` uses Gaussian Mixture Models (GMM) combined with Optimal Transport (OT) in 1D to align impedance histogram distributions across different analysers. This is useful when:\n",
    "\n",
    "- Combining data from multiple analyser machines\n",
    "- Correcting batch effects between analyser units\n",
    "- Training machine learning models on data from one analyser and applying to another\n",
    "\n",
    "## Method\n",
    "\n",
    "1. **Load OutputData.csv**: Impedance data in histogram format (RBC and PLT channels)\n",
    "2. **Fit GMMs**: Gaussian mixture models are fit to both source and target distributions\n",
    "3. **Compute transport**: Optimal transport plan computed between GMM components\n",
    "4. **Transform**: Individual histogram bins are transformed using the transport map\n",
    "5. **Validate**: Compare transformed distribution to target\n",
    "\n",
    "## Data Format\n",
    "\n",
    "Impedance data (`OutputData.csv`) contains:\n",
    "- **Sample No.**: Sample identifier\n",
    "- **RBC_RAW_000 to RBC_RAW_127**: Red blood cell impedance histogram (128 bins, 0-250 fL range, ~1.95 fL bin width)\n",
    "- **PLT_RAW_000 to PLT_RAW_127**: Platelet impedance histogram (128 bins, 0-40 fL range, ~0.31 fL bin width)\n",
    "- Other columns: Metadata and derived parameters\n",
    "\n",
    "**Important**: Column names are always indexed 000-127, but they represent different femtoliter (fL) ranges:\n",
    "- **RBC**: 0-250 fL (full particle size range for red blood cells)\n",
    "- **PLT**: 0-40 fL (zoomed view for smaller platelets - higher resolution in small particle range)\n",
    "\n",
    "\n",
    "Once again, we are using our own Sysmex raw data from the INTERVAL and STRIDES studies. Users will have to replace the data loading sections of this notebook with their own paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# PDF-compatible fonts\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "\n",
    "# Scientific plot style\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use([\"science\", \"nature\"])\n",
    "\n",
    "# Colourblind-friendly palette\n",
    "SEABORN_PALETTE = \"colorblind\"\n",
    "seaborn_colors = sns.color_palette(SEABORN_PALETTE)\n",
    "\n",
    "# Add parent directory to path to import sysmexcbctools\n",
    "# This allows imports to work whether or not the package is installed\n",
    "repo_root = (\n",
    "    Path(__file__).parent.parent.parent\n",
    "    if \"__file__\" in globals()\n",
    "    else Path.cwd().parent.parent\n",
    ")\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "# Import from sysmexcbctools.transfer\n",
    "from sysmexcbctools.transfer.sysmexalign import ImpedanceTransformer\n",
    "from sysmexcbctools.transfer.config import load_config\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"  Repository root: {repo_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data Paths\n",
    "\n",
    "Impedance data is stored in `OutputData.csv` files containing RBC and PLT histogram bins.\n",
    "\n",
    "For this example, we'll use **real data from two different Sysmex analysers**:\n",
    "- **Source**: STRIDES study data\n",
    "- **Target**: INTERVAL study (analyser XN-10^11036)\n",
    "\n",
    "We'll align both RBC and PLT impedance distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration to get data paths\n",
    "config = load_config(str(repo_root / \"sysmexcbctools/transfer/config/data_paths.yaml\"))\n",
    "\n",
    "# Get dataset paths for two different analysers\n",
    "# Source: STRIDES impedance data (directory containing multiple OutputData.csv files)\n",
    "# Target: INTERVAL analyser XN-10^11036 impedance data (single OutputData.csv file)\n",
    "SOURCE_DIR = config[\"datasets\"][\"raw\"][\"strides\"]\n",
    "TARGET_FILE = config[\"datasets\"][\"raw\"][\"interval_36\"] + \"/OutputData.csv\"\n",
    "\n",
    "# Also load sample numbers for filtering (optional but recommended)\n",
    "source_samples_file = config[\"files\"][\"centile_samples\"][\"strides\"]\n",
    "target_samples_file = config[\"files\"][\"centile_samples\"][\"interval_baseline_36\"]\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR = \"../outputs/impedance_transformed/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Data Configuration Loaded:\")\n",
    "print(f\"Source directory: {SOURCE_DIR}\")\n",
    "print(f\"Target file: {TARGET_FILE}\")\n",
    "print(f\"Source samples file: {source_samples_file}\")\n",
    "print(f\"Target samples file: {target_samples_file}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load impedance data\n",
    "print(\"Loading impedance data...\")\n",
    "\n",
    "# Source: Find all OutputData.csv files in subdirectories and concatenate them\n",
    "print(\"\\n1. Loading source data (STRIDES)...\")\n",
    "source_files = sorted(Path(SOURCE_DIR).rglob(\"OutputData.csv\"))\n",
    "print(f\"   Found {len(source_files)} OutputData.csv files in source directory\")\n",
    "\n",
    "if len(source_files) == 0:\n",
    "    raise FileNotFoundError(f\"No OutputData.csv files found in {SOURCE_DIR}\")\n",
    "\n",
    "# Load and concatenate all source files\n",
    "source_dfs = []\n",
    "for i, file in enumerate(source_files, 1):\n",
    "    print(f\"   Loading file {i}/{len(source_files)}: {file.parent.name}/OutputData.csv\")\n",
    "    df = pd.read_csv(file)\n",
    "    source_dfs.append(df)\n",
    "\n",
    "source_df = pd.concat(source_dfs, ignore_index=True)\n",
    "print(f\"   ✓ Concatenated {len(source_files)} files into single DataFrame\")\n",
    "print(f\"   Total source samples: {len(source_df):,}\")\n",
    "\n",
    "# Target: Load single file\n",
    "print(\"\\n2. Loading target data (INTERVAL)...\")\n",
    "target_df = pd.read_csv(TARGET_FILE)\n",
    "print(f\"   Total target samples: {len(target_df):,}\")\n",
    "\n",
    "# Load sample numbers for filtering (recommended for large datasets)\n",
    "source_sample_nos = np.load(source_samples_file, allow_pickle=True)\n",
    "target_sample_nos = np.load(target_samples_file, allow_pickle=True)\n",
    "\n",
    "print(f\"\\n3. Sample filtering:\")\n",
    "print(f\"  Source samples: {len(source_sample_nos):,} centile samples\")\n",
    "print(f\"  Target samples: {len(target_sample_nos):,} centile samples\")\n",
    "\n",
    "# For initial testing, we'll use centile samples\n",
    "USE_CENTILE_SAMPLES = True  # Set to False to use all samples\n",
    "\n",
    "if USE_CENTILE_SAMPLES:\n",
    "    print(\"\\nUsing centile samples for efficient computation...\")\n",
    "    source_df_filtered = source_df[\n",
    "        source_df[\"Sample No.\"].isin(source_sample_nos)\n",
    "    ].copy()\n",
    "    target_df_filtered = target_df[\n",
    "        target_df[\"Sample No.\"].isin(target_sample_nos)\n",
    "    ].copy()\n",
    "\n",
    "    print(f\"  Filtered source: {len(source_df_filtered):,} samples\")\n",
    "    print(f\"  Filtered target: {len(target_df_filtered):,} samples\")\n",
    "else:\n",
    "    source_df_filtered = source_df.copy()\n",
    "    target_df_filtered = target_df.copy()\n",
    "    print(\"\\nUsing all available samples...\")\n",
    "\n",
    "# Display sample of data structure\n",
    "print(\"\\nSample of source data (first 5 columns):\")\n",
    "print(source_df_filtered.iloc[:3, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Transformer\n",
    "\n",
    "Create an `ImpedanceTransformer` with appropriate parameters.\n",
    "\n",
    "**Key Parameter: `gmm_sample_size`**\n",
    "\n",
    "This controls the number of point samples used for GMM fitting. When the total histogram counts exceed this value, the data is downsampled using **probabilistic rounding** to preserve distribution shape.\n",
    "\n",
    "The transformer will:\n",
    "1. Fit separate GMMs for RBC and PLT histogram distributions\n",
    "2. Compute optimal transport between source and target for each channel\n",
    "3. Apply transformations to align histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ImpedanceTransformer(\n",
    "    gmm_sample_size=50000,  # Increased from 1000 to preserve distribution shape\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "print(\"✓ ImpedanceTransformer initialized\")\n",
    "print(f\"  GMM sample size: {transformer.gmm_sample_size:,}\")\n",
    "print(f\"  Parallel jobs: {transformer.n_jobs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit the Transformation\n",
    "\n",
    "Fit GMM models to both source and target distributions for RBC and PLT channels, then compute optimal transport maps.\n",
    "\n",
    "**This step performs the expensive GMM fitting and transport map computation:**\n",
    "1. Fits 4 GMMs (RBC source, RBC target, PLT source, PLT target)\n",
    "2. Computes 2 optimal transport maps (RBC, PLT)\n",
    "3. Stores these for reuse during transformation\n",
    "\n",
    "**Note**: This can take several minutes. Once fitted, you can save the transformer and reuse it for multiple datasets without refitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have data to work with\n",
    "if len(source_df_filtered) == 0 or len(target_df_filtered) == 0:\n",
    "    print(\"⚠ ERROR: No samples found after filtering!\")\n",
    "    print(f\"  Source samples: {len(source_df_filtered)}\")\n",
    "    print(f\"  Target samples: {len(target_df_filtered)}\")\n",
    "    print(\"\\nPossible causes:\")\n",
    "    print(\"  - Data not available on this system (requires HPC/RDS access)\")\n",
    "    print(\"  - Incorrect paths in config/data_paths.yaml\")\n",
    "    print(\"  - Sample number filtering removed all files\")\n",
    "    print(\"\\nTo proceed:\")\n",
    "    print(\"  1. Verify you have access to the RDS data\")\n",
    "    print(\"  2. Check paths in config/data_paths.yaml\")\n",
    "    print(\"  3. Try setting USE_CENTILE_SAMPLES = False in cell above\")\n",
    "else:\n",
    "    print(\n",
    "        f\"✓ Found {len(source_df_filtered):,} source samples and {len(target_df_filtered):,} target samples\"\n",
    "    )\n",
    "    print(\"\\nFitting transformation parameters...\")\n",
    "\n",
    "    # Fit using filtered dataframes\n",
    "    # Pass sample numbers if using centile samples\n",
    "    if USE_CENTILE_SAMPLES:\n",
    "        transformer.fit(\n",
    "            source_df=source_df,\n",
    "            target_df=target_df,\n",
    "            source_sample_nos=source_sample_nos,\n",
    "            target_sample_nos=target_sample_nos,\n",
    "        )\n",
    "    else:\n",
    "        transformer.fit(\n",
    "            source_df=source_df,\n",
    "            target_df=target_df,\n",
    "        )\n",
    "\n",
    "    print(\"\\n✓ Transformer fitted successfully!\")\n",
    "    # print(f\"  Source standards: {len(transformer.source_standards_):,} samples\")\n",
    "    # print(f\"  Target standards: {len(transformer.target_standards_):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Visualise Fitted GMMs\n",
    "\n",
    "Inspect the quality of the fitted GMMs by comparing them to the data used for fitting.\n",
    "\n",
    "This helps debug potential issues:\n",
    "- Are the GMM components well-positioned?\n",
    "- Does the GMM capture the distribution shape?\n",
    "- Are there outliers or unusual patterns?\n",
    "\n",
    "We'll show 4 plots:\n",
    "- **RBC Source GMM** vs source histogram data\n",
    "- **RBC Target GMM** vs target histogram data  \n",
    "- **PLT Source GMM** vs source histogram data (log-transformed)\n",
    "- **PLT Target GMM** vs target histogram data (log-transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Known Limitations\n",
    "\n",
    "**PLT Distribution Shape:**\n",
    "The PLT impedance distribution is Gaussian-like on the left side but has a sharp cutoff on the right side (physical constraint from the 0-40 fL measurement range). This asymmetric shape cannot be perfectly captured by GMMs, which assume Gaussian components. \n",
    "\n",
    "**Observed effects:**\n",
    "- GMM may underfit or overfit certain regions\n",
    "- Transformation quality for PLT may be lower than for RBC\n",
    "- Some artificial spikes may still appear in transformed PLT histograms\n",
    "\n",
    "**Future work:**\n",
    "- Consider truncated Gaussian mixture models for PLT\n",
    "- Investigate alternative distributions (e.g., log-normal, gamma) for PLT components\n",
    "- Explore histogram matching methods that don't assume parametric forms\n",
    "\n",
    "For now, this is an acceptable limitation given the overall transformation quality improvements achieved with increased `gmm_sample_size` and probabilistic rounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not transformer.is_fitted_:\n",
    "    print(\"⚠ Transformer not fitted yet. Skipping GMM visualization.\")\n",
    "else:\n",
    "    from sysmexcbctools.transfer.sysmexalign.alignment_1d import sample_impedance_array\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.stats import norm\n",
    "\n",
    "    print(\"Visualizing fitted GMMs...\")\n",
    "\n",
    "    # Recreate the sampled data used for fitting\n",
    "    class Args:\n",
    "        gmm_sample_size = transformer.gmm_sample_size\n",
    "\n",
    "    args = Args()\n",
    "\n",
    "    # Get standard samples (same as in fit())\n",
    "    source_df_copy = source_df.copy()\n",
    "    target_df_copy = target_df.copy()\n",
    "    source_df_copy[\"IsStandard\"] = (\n",
    "        source_df_copy[\"Sample No.\"].isin(source_sample_nos).astype(int)\n",
    "    )\n",
    "    target_df_copy[\"IsStandard\"] = (\n",
    "        target_df_copy[\"Sample No.\"].isin(target_sample_nos).astype(int)\n",
    "    )\n",
    "\n",
    "    source_standards = source_df_copy[source_df_copy[\"IsStandard\"] == 1]\n",
    "    target_standards = target_df_copy[target_df_copy[\"IsStandard\"] == 1]\n",
    "\n",
    "    # RBC data\n",
    "    source_rbc_data = source_standards.filter(like=\"RBC_RAW_\").sum(axis=0)\n",
    "    target_rbc_data = target_standards.filter(like=\"RBC_RAW_\").sum(axis=0)\n",
    "    X_source_rbc = sample_impedance_array(args, source_rbc_data)\n",
    "    X_target_rbc = sample_impedance_array(args, target_rbc_data)\n",
    "\n",
    "    # PLT data (log-transformed)\n",
    "    source_plt_data = source_standards.filter(like=\"PLT_RAW_\").sum(axis=0)\n",
    "    target_plt_data = target_standards.filter(like=\"PLT_RAW_\").sum(axis=0)\n",
    "    X_source_plt_log = np.log(sample_impedance_array(args, source_plt_data) + 1)\n",
    "    X_target_plt_log = np.log(sample_impedance_array(args, target_plt_data) + 1)\n",
    "\n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(4.5, 4.5))\n",
    "\n",
    "    # Helper function to compute GMM PDF\n",
    "    def plot_gmm_with_data(ax, data, gmm, title, xlabel):\n",
    "        # Plot histogram of data\n",
    "        ax.hist(data, bins=100, density=True, alpha=0.5, color=\"blue\", label=\"Data\")\n",
    "\n",
    "        # Compute GMM PDF\n",
    "        x_range = np.linspace(data.min(), data.max(), 1000).reshape(-1, 1)\n",
    "        log_prob = gmm.score_samples(x_range)\n",
    "        pdf = np.exp(log_prob)\n",
    "\n",
    "        # Plot GMM PDF\n",
    "        ax.plot(\n",
    "            x_range,\n",
    "            pdf,\n",
    "            \"r-\",\n",
    "            linewidth=2,\n",
    "            label=f\"GMM ({gmm.n_components} components)\",\n",
    "        )\n",
    "\n",
    "        # Plot individual Gaussian components\n",
    "        for i in range(gmm.n_components):\n",
    "            mean = gmm.means_[i, 0]\n",
    "            var = gmm.covariances_[i, 0, 0]\n",
    "            weight = gmm.weights_[i]\n",
    "\n",
    "            component_pdf = weight * norm.pdf(x_range, mean, np.sqrt(var))\n",
    "            ax.plot(\n",
    "                x_range,\n",
    "                component_pdf,\n",
    "                \"--\",\n",
    "                alpha=0.5,\n",
    "                label=f\"Component {i+1} ($\\mu$={mean:.1f}, $\\sigma$={np.sqrt(var):.1f})\",\n",
    "            )\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(\"Density\")\n",
    "        ax.set_title(title)\n",
    "        ax.legend(fontsize=5)\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "    # Plot 1: RBC Source\n",
    "    plot_gmm_with_data(\n",
    "        axes[0, 0],\n",
    "        X_source_rbc,\n",
    "        transformer.rbc_source_gmm_,\n",
    "        \"RBC Source GMM Fit\",\n",
    "        \"Bin Index (0-127)\",\n",
    "    )\n",
    "\n",
    "    # Plot 2: RBC Target\n",
    "    plot_gmm_with_data(\n",
    "        axes[0, 1],\n",
    "        X_target_rbc,\n",
    "        transformer.rbc_target_gmm_,\n",
    "        \"RBC Target GMM Fit\",\n",
    "        \"Bin Index (0-127)\",\n",
    "    )\n",
    "\n",
    "    # Plot 3: PLT Source (log-transformed)\n",
    "    plot_gmm_with_data(\n",
    "        axes[1, 0],\n",
    "        X_source_plt_log,\n",
    "        transformer.plt_source_gmm_,\n",
    "        \"PLT Source GMM Fit (Log-Transformed)\",\n",
    "        \"log(Bin Index + 1)\",\n",
    "    )\n",
    "\n",
    "    # Plot 4: PLT Target (log-transformed)\n",
    "    plot_gmm_with_data(\n",
    "        axes[1, 1],\n",
    "        X_target_plt_log,\n",
    "        transformer.plt_target_gmm_,\n",
    "        \"PLT Target GMM Fit (Log-Transformed)\",\n",
    "        \"log(Bin Index + 1)\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../outputs/impedance_gmm_fits.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n✓ GMM fit visualizations saved to ../outputs/impedance_gmm_fits.png\")\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"  - Blue histogram: Actual sampled data used for GMM fitting\")\n",
    "    print(\"  - Red solid line: Overall GMM probability density function\")\n",
    "    print(\"  - Dashed lines: Individual Gaussian components\")\n",
    "    print(\"  - Good fit = red line closely follows blue histogram\")\n",
    "    print(f\"  - RBC GMMs: {transformer.rbc_source_gmm_.n_components} components\")\n",
    "    print(f\"  - PLT GMMs: {transformer.plt_source_gmm_.n_components} components\")\n",
    "\n",
    "    # Print component details\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RBC SOURCE GMM COMPONENTS\")\n",
    "    print(\"=\" * 60)\n",
    "    for i in range(transformer.rbc_source_gmm_.n_components):\n",
    "        mean = transformer.rbc_source_gmm_.means_[i, 0]\n",
    "        var = transformer.rbc_source_gmm_.covariances_[i, 0, 0]\n",
    "        weight = transformer.rbc_source_gmm_.weights_[i]\n",
    "        print(\n",
    "            f\"  Component {i+1}: μ={mean:6.2f}, σ={np.sqrt(var):6.2f}, weight={weight:.3f}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RBC TARGET GMM COMPONENTS\")\n",
    "    print(\"=\" * 60)\n",
    "    for i in range(transformer.rbc_target_gmm_.n_components):\n",
    "        mean = transformer.rbc_target_gmm_.means_[i, 0]\n",
    "        var = transformer.rbc_target_gmm_.covariances_[i, 0, 0]\n",
    "        weight = transformer.rbc_target_gmm_.weights_[i]\n",
    "        print(\n",
    "            f\"  Component {i+1}: μ={mean:6.2f}, σ={np.sqrt(var):6.2f}, weight={weight:.3f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save and Load Transformer\n",
    "\n",
    "Once fitted, you can save the transformer and reuse it later without re-fitting the GMMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fitted transformer for later use\n",
    "# This allows you to skip the time-consuming fitting step in future sessions\n",
    "\n",
    "save_path = \"../outputs/impedance_transformer.pkl\"\n",
    "transformer.save(save_path)\n",
    "print(f\"✓ You can now load this transformer in future sessions to skip re-fitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a previously saved transformer\n",
    "# Uncomment and run this cell if you want to load a saved transformer instead of fitting\n",
    "\n",
    "# from sysmexcbctools.transfer.sysmexalign import ImpedanceTransformer\n",
    "# save_path = \"../outputs/impedance_transformer.pkl\"\n",
    "# transformer = ImpedanceTransformer.load(save_path)\n",
    "# print(f\"✓ Transformer loaded from: {save_path}\")\n",
    "# print(f\"  GMM sample size: {transformer.gmm_sample_size:,}\")\n",
    "# print(f\"  Fitted: {transformer.is_fitted_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transform Source Data\n",
    "\n",
    "Apply the learned transformation to source data. This will:\n",
    "1. Use the pre-computed GMMs and transport maps from fit()\n",
    "2. Transform RBC histograms by converting bins→points→transform→re-bin\n",
    "3. Transform PLT histograms (with log/exp transforms for better Gaussianity)\n",
    "4. Return a transformed DataFrame with aligned distributions\n",
    "\n",
    "**Note**: Unlike fit(), transform() is fast because it reuses the pre-computed GMMs and transport maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the source data using the fitted GMMs and transport maps\n",
    "# This reuses the pre-computed GMMs - no refitting happens here!\n",
    "\n",
    "if not transformer.is_fitted_:\n",
    "    print(\"⚠ ERROR: Transformer not fitted yet. Please run the fit() cell above first.\")\n",
    "else:\n",
    "    print(\"Transforming source data...\")\n",
    "    print(f\"  Input: {len(source_df_filtered):,} samples\")\n",
    "\n",
    "    # Transform creates aligned histograms by:\n",
    "    # 1. Converting histogram bins to points (based on counts)\n",
    "    # 2. Transforming points using pre-computed GMMs and transport maps\n",
    "    # 3. Re-binning transformed points into histograms\n",
    "    transformed_df = transformer.transform(source_df_filtered.copy())\n",
    "\n",
    "    print(f\"✓ Transformation complete!\")\n",
    "    print(f\"  Output: {len(transformed_df):,} samples\")\n",
    "    print(f\"  Columns transformed: RBC_RAW_* and PLT_RAW_* histograms\")\n",
    "\n",
    "    # Display sample of transformed data\n",
    "    print(\"\\nSample of transformed data (first 5 columns):\")\n",
    "    print(transformed_df.iloc[:3, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validate Transformation Quality\n",
    "\n",
    "Visualize the alignment quality by comparing source, target, and transformed distributions.\n",
    "\n",
    "We'll create 4-panel plots showing:\n",
    "- **Top row**: RBC impedance histograms (before and after transformation)\n",
    "- **Bottom row**: PLT impedance histograms (before and after transformation)\n",
    "- **Left column**: Original source (blue) vs target (orange) - shows initial misalignment\n",
    "- **Right column**: Transformed (green) vs target (orange) - should overlap if transformation worked well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not transformer.is_fitted_ or \"transformed_df\" not in locals():\n",
    "    print(\n",
    "        \"⚠ Transformer not fitted or transformation not performed. Skipping visualization.\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Creating distribution comparison plots...\")\n",
    "\n",
    "    # Extract RBC and PLT histogram columns\n",
    "    rbc_cols = [col for col in source_df_filtered.columns if col.startswith(\"RBC_RAW\")]\n",
    "    plt_cols = [col for col in source_df_filtered.columns if col.startswith(\"PLT_RAW\")]\n",
    "\n",
    "    print(f\"  Found {len(rbc_cols)} RBC histogram bins\")\n",
    "    print(f\"  Found {len(plt_cols)} PLT histogram bins\")\n",
    "\n",
    "    # Create bin centers (fL) - columns are indices 0-127, but represent different fL ranges\n",
    "    # RBC: 128 bins spanning 0-250 fL (bin width ~1.95 fL)\n",
    "    # PLT: 128 bins spanning 0-40 fL (bin width ~0.31 fL) - zoomed view for smaller particles\n",
    "    rbc_bins = np.linspace(0, 250, len(rbc_cols))\n",
    "    plt_bins = np.linspace(0, 40, len(plt_cols))\n",
    "\n",
    "    # Compute average histograms\n",
    "    source_rbc_avg = source_df_filtered[rbc_cols].mean(axis=0).values\n",
    "    target_rbc_avg = target_df_filtered[rbc_cols].mean(axis=0).values\n",
    "    transformed_rbc_avg = transformed_df[rbc_cols].mean(axis=0).values\n",
    "\n",
    "    source_plt_avg = source_df_filtered[plt_cols].mean(axis=0).values\n",
    "    target_plt_avg = target_df_filtered[plt_cols].mean(axis=0).values\n",
    "    transformed_plt_avg = transformed_df[plt_cols].mean(axis=0).values\n",
    "\n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(4.5, 4.5))\n",
    "\n",
    "    # ========== RBC Histograms ==========\n",
    "    # Panel 1: RBC - Before transformation\n",
    "    ax = axes[0, 0]\n",
    "    ax.plot(\n",
    "        rbc_bins,\n",
    "        source_rbc_avg,\n",
    "        label=\"Source (STRIDES)\",\n",
    "        color=\"blue\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax.plot(\n",
    "        rbc_bins,\n",
    "        target_rbc_avg,\n",
    "        label=\"Target (INTERVAL)\",\n",
    "        color=\"orange\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax.set_xlabel(\"Volume (fL)\")\n",
    "    ax.set_ylabel(\"Average Count\")\n",
    "    ax.set_title(\"RBC Impedance - Before Transformation\")\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    # Panel 2: RBC - After transformation\n",
    "    ax = axes[0, 1]\n",
    "    ax.plot(\n",
    "        rbc_bins,\n",
    "        transformed_rbc_avg,\n",
    "        label=\"Transformed\",\n",
    "        color=\"green\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax.plot(\n",
    "        rbc_bins,\n",
    "        target_rbc_avg,\n",
    "        label=\"Target (INTERVAL)\",\n",
    "        color=\"orange\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax.set_xlabel(\"Volume (fL)\")\n",
    "    ax.set_ylabel(\"Average Count\")\n",
    "    ax.set_title(\"RBC Impedance - After Transformation\")\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    # ========== PLT Histograms ==========\n",
    "    # Panel 3: PLT - Before transformation\n",
    "    ax = axes[1, 0]\n",
    "    ax.plot(\n",
    "        plt_bins,\n",
    "        source_plt_avg,\n",
    "        label=\"Source (STRIDES)\",\n",
    "        color=\"blue\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax.plot(\n",
    "        plt_bins,\n",
    "        target_plt_avg,\n",
    "        label=\"Target (INTERVAL)\",\n",
    "        color=\"orange\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax.set_xlabel(\"Volume (fL)\")\n",
    "    ax.set_ylabel(\"Average Count\")\n",
    "    ax.set_title(\"PLT Impedance - Before Transformation\")\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    # Panel 4: PLT - After transformation\n",
    "    ax = axes[1, 1]\n",
    "    ax.plot(\n",
    "        plt_bins,\n",
    "        transformed_plt_avg,\n",
    "        label=\"Transformed\",\n",
    "        color=\"green\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax.plot(\n",
    "        plt_bins,\n",
    "        target_plt_avg,\n",
    "        label=\"Target (INTERVAL)\",\n",
    "        color=\"orange\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax.set_xlabel(\"Volume (fL)\")\n",
    "    ax.set_ylabel(\"Average Count\")\n",
    "    ax.set_title(\"PLT Impedance - After Transformation\")\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../outputs/impedance_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n✓ Distribution plots saved to ../outputs/impedance_comparison.png\")\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"  - Top row: RBC impedance histograms before and after transformation\")\n",
    "    print(\"  - Bottom row: PLT impedance histograms before and after transformation\")\n",
    "    print(\"  - Left column: Original source (blue) vs target (orange)\")\n",
    "    print(\"  - Right column: Transformed (green) should match target (orange)\")\n",
    "    print(\"  - Success = green and orange curves overlap well\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bloodcounts_sysmex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
