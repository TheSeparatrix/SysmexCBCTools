{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dis-AE 2: Real Data Example with data_B.csv\n",
    "\n",
    "This notebook demonstrates using Dis-AE 2 on the **data_B.csv** synthetic dataset, which simulates real-world challenges:\n",
    "- **Multiple domain factors (modelled after domain shifts found in CBC data)**: Machine, venepuncture delay, study time\n",
    "- **Task**: Binary classification with CBC-like features\n",
    "\n",
    "## Goals\n",
    "\n",
    "1. Train a domain-invariant model for classification\n",
    "2. Evaluate task performance across different domains\n",
    "3. Verify domain invariance in learned features\n",
    "4. Compare with baseline methods (no domain adaptation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sysmexcbctools.disae2.disae2 import DisAE, normalize_data\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# PDF-compatible fonts\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "\n",
    "# Scientific plot style\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use([\"science\", \"nature\"])\n",
    "\n",
    "# Colourblind-friendly palette\n",
    "SEABORN_PALETTE = \"colorblind\"\n",
    "seaborn_colors = sns.color_palette(SEABORN_PALETTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data_B.csv\n",
    "data_path = \"../data/data_B.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset summary\n",
    "print(\"Dataset Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total samples: {len(df):,}\")\n",
    "print(f\"Features: 32 (columns 0-31)\")\n",
    "print(f\"\\nTask label: ClassCategory_0\")\n",
    "print(f\"  Class distribution:\")\n",
    "print(df[\"ClassCategory_0\"].value_counts().sort_index())\n",
    "print(f\"\\nDomain factors:\")\n",
    "print(f\"  Machine: {df['Machine'].nunique()} levels\")\n",
    "print(f\"  vendelay_binned: {df['vendelay_binned'].nunique()} bins\")\n",
    "print(f\"  studytime_binned: {df['studytime_binned'].nunique()} bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Domain Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot domain factor distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(6.6, 2.2))\n",
    "\n",
    "df[\"Machine\"].value_counts().sort_index().plot(\n",
    "    kind=\"bar\", ax=axes[0], color=\"steelblue\"\n",
    ")\n",
    "axes[0].set_title(\"Machine Distribution\")\n",
    "axes[0].set_xlabel(\"Machine ID\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=0)\n",
    "\n",
    "df[\"vendelay_binned\"].value_counts().sort_index().plot(\n",
    "    kind=\"bar\", ax=axes[1], color=\"coral\"\n",
    ")\n",
    "axes[1].set_title(\"Venepuncture Delay Distribution\")\n",
    "axes[1].set_xlabel(\"Delay Bin\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=0)\n",
    "\n",
    "df[\"studytime_binned\"].value_counts().sort_index().plot(\n",
    "    kind=\"bar\", ax=axes[2], color=\"mediumseagreen\"\n",
    ")\n",
    "axes[2].set_title(\"Study Time Distribution\")\n",
    "axes[2].set_xlabel(\"Time Bin\")\n",
    "axes[2].set_ylabel(\"Count\")\n",
    "axes[2].tick_params(axis=\"x\", rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "feature_columns = [str(i) for i in range(32)]  # Columns are just named \"0\" to \"31\"\n",
    "X = df[feature_columns].values\n",
    "\n",
    "# Task label (binary classification)\n",
    "y_task = df[\"ClassCategory_0\"].values.reshape(-1, 1)\n",
    "\n",
    "# Domain factors\n",
    "domain_columns = [\"Machine\", \"vendelay_binned\", \"studytime_binned\"]\n",
    "y_domains_raw = df[domain_columns]\n",
    "\n",
    "# Encode domain labels as integers\n",
    "y_domains = []\n",
    "domain_mappings = {}\n",
    "for col in domain_columns:\n",
    "    le = LabelEncoder()\n",
    "    encoded = le.fit_transform(y_domains_raw[col])\n",
    "    y_domains.append(encoded)\n",
    "    domain_mappings[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "y_domains = np.column_stack(y_domains)\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(f\"  X: {X.shape}\")\n",
    "print(f\"  y_task: {y_task.shape}\")\n",
    "print(f\"  y_domains: {y_domains.shape}\")\n",
    "print(\n",
    "    f\"\\nDomain cardinalities: {[len(np.unique(y_domains[:, i])) for i in range(y_domains.shape[1])]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Feature statistics after normalisation:\")\n",
    "print(f\"  Mean: {X_normalized.mean():.6f}\")\n",
    "print(f\"  Std: {X_normalized.std():.6f}\")\n",
    "print(f\"  Min: {X_normalized.min():.4f}\")\n",
    "print(f\"  Max: {X_normalized.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain Generalization Split Strategy:\n",
    "# - Train/Val: Machines 0 and 1 (source domains)\n",
    "# - Test: Machines 2, 3, 4 (target domains) + small portion of 0, 1 (within-source)\n",
    "\n",
    "# Split by machine ID\n",
    "machine_ids = y_domains[:, 0]\n",
    "\n",
    "# Source domains (train + val): machines 0 and 1\n",
    "source_mask = np.isin(machine_ids, [0, 1])\n",
    "X_source = X_normalized[source_mask]\n",
    "y_task_source = y_task[source_mask]\n",
    "y_domains_source = y_domains[source_mask]\n",
    "\n",
    "# Target domains (test): machines 2, 3, 4\n",
    "target_mask = np.isin(machine_ids, [2, 3, 4])\n",
    "X_target = X_normalized[target_mask]\n",
    "y_task_target = y_task[target_mask]\n",
    "y_domains_target = y_domains[target_mask]\n",
    "\n",
    "# Also create a small within-source test set (10% of source data)\n",
    "(\n",
    "    X_source_train_val,\n",
    "    X_source_test,\n",
    "    y_task_source_train_val,\n",
    "    y_task_source_test,\n",
    "    y_domains_source_train_val,\n",
    "    y_domains_source_test,\n",
    ") = train_test_split(\n",
    "    X_source,\n",
    "    y_task_source,\n",
    "    y_domains_source,\n",
    "    test_size=0.1,\n",
    "    stratify=y_domains_source[:, 0],  # Stratify by machine within source\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Split source into train and val (80/20 of remaining source data)\n",
    "X_train, X_val, y_task_train, y_task_val, y_domains_train, y_domains_val = (\n",
    "    train_test_split(\n",
    "        X_source_train_val,\n",
    "        y_task_source_train_val,\n",
    "        y_domains_source_train_val,\n",
    "        test_size=0.2,\n",
    "        stratify=y_domains_source_train_val[:, 0],\n",
    "        random_state=42,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine within-source and target test sets\n",
    "X_test_within_source = X_source_test\n",
    "y_task_test_within_source = y_task_source_test\n",
    "y_domains_test_within_source = y_domains_source_test\n",
    "\n",
    "X_test_target = X_target\n",
    "y_task_test_target = y_task_target\n",
    "y_domains_test_target = y_domains_target\n",
    "\n",
    "# Combined test set\n",
    "X_test = np.vstack([X_test_within_source, X_test_target])\n",
    "y_task_test = np.vstack([y_task_test_within_source, y_task_test_target])\n",
    "y_domains_test = np.vstack([y_domains_test_within_source, y_domains_test_target])\n",
    "\n",
    "print(\"Domain Generalization Split Strategy:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Source domains (machines 0, 1): {source_mask.sum():,} samples\")\n",
    "print(f\"Target domains (machines 2, 3, 4): {target_mask.sum():,} samples\")\n",
    "print(f\"\\nDataset splits:\")\n",
    "print(\n",
    "    f\"  Train:                 {X_train.shape[0]:,} samples ({X_train.shape[0] / len(X) * 100:.1f}%) - Machines 0, 1\"\n",
    ")\n",
    "print(\n",
    "    f\"  Val:                   {X_val.shape[0]:,} samples ({X_val.shape[0] / len(X) * 100:.1f}%) - Machines 0, 1\"\n",
    ")\n",
    "print(\n",
    "    f\"  Test (within-source):  {X_test_within_source.shape[0]:,} samples ({X_test_within_source.shape[0] / len(X) * 100:.1f}%) - Machines 0, 1\"\n",
    ")\n",
    "print(\n",
    "    f\"  Test (target):         {X_test_target.shape[0]:,} samples ({X_test_target.shape[0] / len(X) * 100:.1f}%) - Machines 2, 3, 4\"\n",
    ")\n",
    "print(\n",
    "    f\"  Test (combined):       {X_test.shape[0]:,} samples ({X_test.shape[0] / len(X) * 100:.1f}%)\"\n",
    ")\n",
    "\n",
    "# Verify machine distribution\n",
    "print(f\"\\nMachine distribution in splits:\")\n",
    "for split_name, split_domains in [\n",
    "    (\"Train\", y_domains_train),\n",
    "    (\"Val\", y_domains_val),\n",
    "    (\"Test (within-source)\", y_domains_test_within_source),\n",
    "    (\"Test (target)\", y_domains_test_target),\n",
    "]:\n",
    "    machine_counts = np.bincount(split_domains[:, 0])\n",
    "    print(f\"  {split_name:20s}: {dict(enumerate(machine_counts[machine_counts > 0]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Model (No Domain Adaptation)\n",
    "\n",
    "First, let's train a simple logistic regression as a baseline to compare against Dis-AE 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline logistic regression\n",
    "baseline_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "baseline_model.fit(X_train, y_task_train.ravel())\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "baseline_acc = accuracy_score(y_task_test, y_pred_baseline)\n",
    "\n",
    "print(\"Baseline Model (Logistic Regression):\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Overall test accuracy: {baseline_acc:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_task_test, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-domain baseline performance\n",
    "print(\"\\nPer-domain baseline accuracy:\")\n",
    "print(\"=\" * 60)\n",
    "for domain_idx, domain_name in enumerate(domain_columns):\n",
    "    print(f\"\\n{domain_name}:\")\n",
    "    domain_values = np.unique(y_domains_test[:, domain_idx])\n",
    "    for val in domain_values:\n",
    "        mask = y_domains_test[:, domain_idx] == val\n",
    "        if mask.sum() > 0:\n",
    "            domain_acc = accuracy_score(y_task_test[mask], y_pred_baseline[mask])\n",
    "            print(f\"  Level {val}: {domain_acc:.4f} ({mask.sum()} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Dis-AE 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Dis-AE 2\n",
    "num_domains = [\n",
    "    len(np.unique(y_domains_train[:, i])) for i in range(y_domains_train.shape[1])\n",
    "]\n",
    "\n",
    "model = DisAE(\n",
    "    input_dim=32,\n",
    "    latent_dim=16,\n",
    "    shared_dim=8,\n",
    "    private_dim=8,\n",
    "    num_tasks=[2],  # Binary classification\n",
    "    num_domains=num_domains,  # [5, 10, 10]\n",
    "    hidden_dims=[64, 32],\n",
    "    reconstruction_weight=0.1,\n",
    "    adversarial_weight=1.0,\n",
    "    orthogonality_weight=0.1,\n",
    "    learning_rate=0.01,\n",
    "    batch_size=256,\n",
    "    device=\"cpu\",  # Change to 'cuda' if GPU available\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"Dis-AE 2 Model Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Input dimension: {model.input_dim}\")\n",
    "print(f\"Latent dimension: {model.latent_dim}\")\n",
    "print(f\"  - Shared: {model.shared_dim}\")\n",
    "print(f\"  - Private: {model.private_dim}\")\n",
    "print(f\"Tasks: {model.num_tasks}\")\n",
    "print(f\"Domain factors: {model.num_domains}\")\n",
    "print(f\"Batch size: {model.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"\\nTraining Dis-AE 2...\\n\")\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_task_train,\n",
    "    y_domains_train,\n",
    "    X_val=X_val,\n",
    "    y_tasks_val=y_task_val,\n",
    "    y_domains_val=y_domains_val,\n",
    "    max_epochs=100,\n",
    "    early_stopping_patience=16,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Dis-AE 2 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall test accuracy\n",
    "y_pred_disae = model.predict_tasks(X_test)[0]\n",
    "disae_acc = accuracy_score(y_task_test, y_pred_disae)\n",
    "\n",
    "print(\"Dis-AE 2 Test Performance:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Overall test accuracy: {disae_acc:.4f}\")\n",
    "print(f\"Baseline accuracy: {baseline_acc:.4f}\")\n",
    "print(\n",
    "    f\"Improvement: {(disae_acc - baseline_acc):.4f} ({(disae_acc - baseline_acc) / baseline_acc * 100:+.2f}%)\"\n",
    ")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_task_test, y_pred_disae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(4.5, 2.2))\n",
    "\n",
    "cm_baseline = confusion_matrix(y_task_test, y_pred_baseline)\n",
    "cm_disae = confusion_matrix(y_task_test, y_pred_disae)\n",
    "\n",
    "sns.heatmap(cm_baseline, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[0])\n",
    "axes[0].set_title(f\"Baseline Confusion Matrix\\n(Acc: {baseline_acc:.4f}\")\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"True\")\n",
    "\n",
    "sns.heatmap(cm_disae, annot=True, fmt=\"d\", cmap=\"Greens\", ax=axes[1])\n",
    "axes[1].set_title(f\"Dis-AE 2 Confusion Matrix\\n(Acc: {disae_acc:.4f})\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"True\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within-Source vs Target Domain Performance\n",
    "print(\"\\nDomain Generalization Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Baseline performance\n",
    "y_pred_baseline_within = baseline_model.predict(X_test_within_source)\n",
    "y_pred_baseline_target = baseline_model.predict(X_test_target)\n",
    "\n",
    "baseline_acc_within = accuracy_score(y_task_test_within_source, y_pred_baseline_within)\n",
    "baseline_acc_target = accuracy_score(y_task_test_target, y_pred_baseline_target)\n",
    "\n",
    "# Dis-AE 2 performance\n",
    "y_pred_disae_within = model.predict_tasks(X_test_within_source)[0]\n",
    "y_pred_disae_target = model.predict_tasks(X_test_target)[0]\n",
    "\n",
    "disae_acc_within = accuracy_score(y_task_test_within_source, y_pred_disae_within)\n",
    "disae_acc_target = accuracy_score(y_task_test_target, y_pred_disae_target)\n",
    "\n",
    "print(\"\\nBaseline (Logistic Regression):\")\n",
    "print(f\"  Within-source (machines 0, 1): {baseline_acc_within:.4f}\")\n",
    "print(f\"  Target domains (machines 2-4):  {baseline_acc_target:.4f}\")\n",
    "print(\n",
    "    f\"  Domain gap:                     {baseline_acc_within - baseline_acc_target:.4f}\"\n",
    ")\n",
    "\n",
    "print(\"\\nDis-AE 2:\")\n",
    "print(f\"  Within-source (machines 0, 1): {disae_acc_within:.4f}\")\n",
    "print(f\"  Target domains (machines 2-4):  {disae_acc_target:.4f}\")\n",
    "print(f\"  Domain gap:                     {disae_acc_within - disae_acc_target:.4f}\")\n",
    "\n",
    "print(\"\\nDomain Gap Reduction:\")\n",
    "baseline_gap = baseline_acc_within - baseline_acc_target\n",
    "disae_gap = disae_acc_within - disae_acc_target\n",
    "gap_reduction = baseline_gap - disae_gap\n",
    "print(f\"  Baseline domain gap:  {baseline_gap:.4f}\")\n",
    "print(f\"  Dis-AE 2 domain gap:  {disae_gap:.4f}\")\n",
    "print(\n",
    "    f\"  Gap reduction:        {gap_reduction:.4f} ({gap_reduction / baseline_gap * 100:.1f}%)\"\n",
    ")\n",
    "print(f\"\\n✓ Smaller domain gap indicates better domain generalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Domain Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline vs Dis-AE 2 per domain\n",
    "results = []\n",
    "\n",
    "for domain_idx, domain_name in enumerate(domain_columns):\n",
    "    domain_values = np.unique(y_domains_test[:, domain_idx])\n",
    "    for val in domain_values:\n",
    "        mask = y_domains_test[:, domain_idx] == val\n",
    "        if mask.sum() > 0:\n",
    "            baseline_domain_acc = accuracy_score(\n",
    "                y_task_test[mask], y_pred_baseline[mask]\n",
    "            )\n",
    "            disae_domain_acc = accuracy_score(y_task_test[mask], y_pred_disae[mask])\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Domain\": domain_name,\n",
    "                    \"Level\": val,\n",
    "                    \"Baseline\": baseline_domain_acc,\n",
    "                    \"DisAE2\": disae_domain_acc,\n",
    "                    \"Improvement\": disae_domain_acc - baseline_domain_acc,\n",
    "                    \"Samples\": mask.sum(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nPer-Domain Accuracy Comparison:\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise per-domain performance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(6.6, 2.2))\n",
    "\n",
    "for idx, domain_name in enumerate(domain_columns):\n",
    "    domain_data = results_df[results_df[\"Domain\"] == domain_name]\n",
    "\n",
    "    x = np.arange(len(domain_data))\n",
    "    width = 0.35\n",
    "\n",
    "    axes[idx].bar(\n",
    "        x - width / 2, domain_data[\"Baseline\"], width, label=\"Baseline\", alpha=0.8\n",
    "    )\n",
    "    axes[idx].bar(\n",
    "        x + width / 2, domain_data[\"DisAE2\"], width, label=\"Dis-AE 2\", alpha=0.8\n",
    "    )\n",
    "\n",
    "    axes[idx].set_xlabel(\"Level\")\n",
    "    axes[idx].set_ylabel(\"Accuracy\")\n",
    "    axes[idx].set_title(f\"{domain_name}\")\n",
    "    axes[idx].set_xticks(x)\n",
    "    axes[idx].set_xticklabels(domain_data[\"Level\"])\n",
    "    axes[idx].legend()\n",
    "    # axes[idx].set_ylim([0.48, 1.0])  # Adjust as needed\n",
    "    axes[idx].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMean improvement across all domains: {results_df['Improvement'].mean():.4f}\")\n",
    "print(f\"Std of accuracy (Baseline): {results_df['Baseline'].std():.4f}\")\n",
    "print(f\"Std of accuracy (Dis-AE 2): {results_df['DisAE2'].std():.4f}\")\n",
    "print(\n",
    "    \"\\nWe can see that Dis-AE 2 learns the type of affine shift present on domain instances 0 and 1 (which is only slightly varied in 2 and 3).\"\n",
    ")\n",
    "print(\n",
    "    \"However, instance 4 is shifted on different features and hence Dis-AE 2 struggles to adapt - even to the point of decreased performance.\"\n",
    ")\n",
    "print(\n",
    "    \"This is typical behaviour in domain generalisation methods, where completely new types of domain shifts can be very challenging.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here onwards, we will take out Machine domain instance 4 to investigate the test set performance more faithfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_no_machine4 = y_domains_test[:, 0] != 4\n",
    "X_test = X_test[mask_no_machine4]\n",
    "y_domains_test = y_domains_test[mask_no_machine4]\n",
    "y_task_test = y_task_test[mask_no_machine4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Domain Invariance Verification\n",
    "\n",
    "Check if discriminators can predict domain from shared features (should be poor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain prediction accuracy\n",
    "d_pred = model.predict_domains(X_test)\n",
    "\n",
    "print(\"Domain Prediction Accuracy (Lower = Better Domain Invariance):\")\n",
    "print(\"=\" * 60)\n",
    "for i, domain_name in enumerate(domain_columns):\n",
    "    domain_acc = accuracy_score(y_domains_test[:, i], d_pred[i])\n",
    "    random_chance = 1.0 / model.num_domains[i]\n",
    "    print(f\"\\n{domain_name}:\")\n",
    "    print(f\"  Accuracy: {domain_acc:.4f}\")\n",
    "    print(f\"  Random chance: {random_chance:.4f}\")\n",
    "    print(f\"  Ratio: {domain_acc / random_chance:.2f}x random\")\n",
    "    if domain_acc <= random_chance * 1.3:\n",
    "        print(f\"  ✓ Good domain invariance!\")\n",
    "    else:\n",
    "        print(f\"  ⚠ Some domain information may be present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings\n",
    "shared_train, private_train = model.embed(X_train, private=True)\n",
    "shared_test, private_test = model.embed(X_test, private=True)\n",
    "\n",
    "print(\"Embedding Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shared features: {shared_test.shape}\")\n",
    "print(f\"Private features: {private_test.shape}\")\n",
    "print(f\"\\nShared features (test):\")\n",
    "print(f\"  Mean: {shared_test.mean():.4f}\")\n",
    "print(f\"  Std: {shared_test.std():.4f}\")\n",
    "print(f\"\\nPrivate features (test):\")\n",
    "print(f\"  Mean: {private_test.mean():.4f}\")\n",
    "print(f\"  Std: {private_test.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Shared Features (Task-Relevant, Domain-Invariant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out machine 4 and subsample to max 1000 samples per machine for visualization\n",
    "mask_no_machine4 = y_domains_test[:, 0] != 4\n",
    "\n",
    "# Subsample each machine to max 1000 samples\n",
    "np.random.seed(42)\n",
    "indices_to_keep = []\n",
    "for machine_id in np.unique(y_domains_test[mask_no_machine4, 0]):\n",
    "    machine_mask = (y_domains_test[:, 0] == machine_id) & mask_no_machine4\n",
    "    machine_indices = np.where(machine_mask)[0]\n",
    "\n",
    "    if len(machine_indices) > 1000:\n",
    "        # Randomly sample 1000 indices\n",
    "        sampled_indices = np.random.choice(machine_indices, size=1000, replace=False)\n",
    "        indices_to_keep.append(sampled_indices)\n",
    "    else:\n",
    "        indices_to_keep.append(machine_indices)\n",
    "\n",
    "indices_to_keep = np.concatenate(indices_to_keep)\n",
    "indices_to_keep.sort()  # Keep sorted for consistency\n",
    "\n",
    "shared_test_filtered = shared_test[indices_to_keep]\n",
    "y_task_test_filtered = y_task_test[indices_to_keep]\n",
    "y_domains_test_filtered = y_domains_test[indices_to_keep]\n",
    "\n",
    "print(f\"Filtered visualization data: {len(indices_to_keep)} samples\")\n",
    "print(f\"Samples per machine: {np.bincount(y_domains_test_filtered[:, 0].astype(int))}\")\n",
    "\n",
    "# we can use PCA or PHATE\n",
    "USE_PHATE = False\n",
    "\n",
    "if USE_PHATE:\n",
    "    import phate\n",
    "\n",
    "    phate_op = phate.PHATE(n_components=2, random_state=42)\n",
    "    pca_shared = phate_op.fit_transform(shared_test_filtered)\n",
    "else:\n",
    "    # PCA on shared features\n",
    "    pca_shared = PCA(n_components=2).fit_transform(shared_test_filtered)\n",
    "\n",
    "# Set axis labels based on method\n",
    "xlabel = \"PHATE1\" if USE_PHATE else \"PC1\"\n",
    "ylabel = \"PHATE2\" if USE_PHATE else \"PC2\"\n",
    "\n",
    "# Create custom colormaps from seaborn_colors\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "task_colors = seaborn_colors[:2]  # First two colors for binary task\n",
    "machine_colors = seaborn_colors[2:]  # Remaining colors for machines\n",
    "task_cmap = ListedColormap(task_colors)\n",
    "machine_cmap = ListedColormap(machine_colors)\n",
    "\n",
    "with plt.style.context([\"science\", \"nature\", \"scatter\"]):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(4.5, 2.2))\n",
    "\n",
    "    # Coloured by task\n",
    "    scatter1 = axes[0].scatter(\n",
    "        pca_shared[:, 0],\n",
    "        pca_shared[:, 1],\n",
    "        c=y_task_test_filtered.ravel(),\n",
    "        cmap=task_cmap,\n",
    "        s=5,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    axes[0].set_title(\"Shared Features - Coloured by Task\")\n",
    "    axes[0].set_xlabel(xlabel)\n",
    "    axes[0].set_ylabel(ylabel)\n",
    "    plt.colorbar(scatter1, ax=axes[0], label=\"Task Label\")\n",
    "\n",
    "    # Coloured by domain (Machine)\n",
    "    scatter2 = axes[1].scatter(\n",
    "        pca_shared[:, 0],\n",
    "        pca_shared[:, 1],\n",
    "        c=y_domains_test_filtered[:, 0],\n",
    "        cmap=machine_cmap,\n",
    "        s=5,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    axes[1].set_title(\"Shared Features - Coloured by Machine\")\n",
    "    axes[1].set_xlabel(xlabel)\n",
    "    axes[1].set_ylabel(ylabel)\n",
    "    plt.colorbar(scatter2, ax=axes[1], label=\"Machine ID\")\n",
    "\n",
    "    plt.tight_layout()  # print(\"✓ Shared features should show task separation (left) but NOT domain separation (right)\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Private Features (Domain-Specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter private features using the same indices\n",
    "private_test_filtered = private_test[indices_to_keep]\n",
    "\n",
    "# we can use PCA or PHATE\n",
    "if USE_PHATE:\n",
    "    import phate\n",
    "\n",
    "    phate_op = phate.PHATE(n_components=2, random_state=42)\n",
    "    pca_private = phate_op.fit_transform(private_test_filtered)\n",
    "\n",
    "else:\n",
    "    # PCA on private features\n",
    "    pca_private = PCA(n_components=2).fit_transform(private_test_filtered)\n",
    "\n",
    "with plt.style.context([\"science\", \"nature\", \"scatter\"]):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(4.5, 2.2))\n",
    "\n",
    "    # Coloured by task\n",
    "    scatter1 = axes[0].scatter(\n",
    "        pca_private[:, 0],\n",
    "        pca_private[:, 1],\n",
    "        c=y_task_test_filtered.ravel(),\n",
    "        cmap=task_cmap,\n",
    "        s=5,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    axes[0].set_title(\"Private Features - Coloured by Task\")\n",
    "    axes[0].set_xlabel(xlabel)\n",
    "    axes[0].set_ylabel(ylabel)\n",
    "    plt.colorbar(scatter1, ax=axes[0], label=\"Task Label\")\n",
    "\n",
    "    # Coloured by domain (Machine)\n",
    "    scatter2 = axes[1].scatter(\n",
    "        pca_private[:, 0],\n",
    "        pca_private[:, 1],\n",
    "        c=y_domains_test_filtered[:, 0],\n",
    "        cmap=machine_cmap,\n",
    "        s=5,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    axes[1].set_title(\"Private Features - Coloured by Machine\")\n",
    "    axes[1].set_xlabel(xlabel)\n",
    "    axes[1].set_ylabel(ylabel)\n",
    "    plt.colorbar(scatter2, ax=axes[1], label=\"Machine ID\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# print(\"✓ Private features can contain domain information for reconstruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined visualization: Shared and Private features (without machine 4)\n",
    "with plt.style.context([\"science\", \"nature\", \"scatter\"]):\n",
    "    # Calculate figure size: 2 columns of 2.2 each, with some spacing\n",
    "    fig_width = 2 * 2.2 + 0.3  # Extra space for spacing and labels\n",
    "    # Calculate height: 2 rows of 2.2 + legend row (taller for stacked legend)\n",
    "    fig_height = 2 * 2.2 + 1.2  # Extra space for legend row\n",
    "\n",
    "    fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "    # Create a 3x2 grid with GridSpec for custom layout\n",
    "    from matplotlib import gridspec\n",
    "\n",
    "    gs = gridspec.GridSpec(\n",
    "        3, 2, figure=fig, height_ratios=[2.2, 2.2, 1.2], hspace=0.15, wspace=0.2\n",
    "    )\n",
    "\n",
    "    # Row 0: Shared features\n",
    "    ax00 = fig.add_subplot(gs[0, 0])\n",
    "    ax01 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    # Row 1: Private features\n",
    "    ax10 = fig.add_subplot(gs[1, 0])\n",
    "    ax11 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "    # Row 2: Legends (invisible axes)\n",
    "    ax20 = fig.add_subplot(gs[2, 0])\n",
    "    ax21 = fig.add_subplot(gs[2, 1])\n",
    "\n",
    "    # Plot shared features - colored by task\n",
    "    scatter00 = ax00.scatter(\n",
    "        pca_shared[:, 0],\n",
    "        pca_shared[:, 1],\n",
    "        c=y_task_test_filtered.ravel(),\n",
    "        cmap=task_cmap,\n",
    "        s=5,\n",
    "        alpha=0.2,\n",
    "        rasterized=True,\n",
    "    )\n",
    "    ax00.set_ylabel(ylabel)\n",
    "    ax00.set_xticklabels([])  # Remove x-tick labels\n",
    "\n",
    "    # Plot shared features - colored by machine\n",
    "    scatter01 = ax01.scatter(\n",
    "        pca_shared[:, 0],\n",
    "        pca_shared[:, 1],\n",
    "        c=y_domains_test_filtered[:, 0],\n",
    "        cmap=machine_cmap,\n",
    "        s=5,\n",
    "        alpha=0.2,\n",
    "        rasterized=True,\n",
    "    )\n",
    "    ax01.set_xticklabels([])  # Remove x-tick labels\n",
    "    ax01.set_yticklabels([])  # Remove y-tick labels\n",
    "\n",
    "    # Plot private features - colored by task\n",
    "    scatter10 = ax10.scatter(\n",
    "        pca_private[:, 0],\n",
    "        pca_private[:, 1],\n",
    "        c=y_task_test_filtered.ravel(),\n",
    "        cmap=task_cmap,\n",
    "        s=5,\n",
    "        alpha=0.2,\n",
    "        rasterized=True,\n",
    "    )\n",
    "    ax10.set_xlabel(xlabel)\n",
    "    ax10.set_ylabel(ylabel)\n",
    "\n",
    "    # Plot private features - colored by machine\n",
    "    scatter11 = ax11.scatter(\n",
    "        pca_private[:, 0],\n",
    "        pca_private[:, 1],\n",
    "        c=y_domains_test_filtered[:, 0],\n",
    "        cmap=machine_cmap,\n",
    "        s=5,\n",
    "        alpha=0.2,\n",
    "        rasterized=True,\n",
    "    )\n",
    "    ax11.set_xlabel(xlabel)\n",
    "    ax11.set_yticklabels([])  # Remove y-tick labels\n",
    "\n",
    "    # Add row labels on the right side - vertically centered and closer to plots\n",
    "    # For shared features (row 0): center between top and middle of figure\n",
    "    fig.text(\n",
    "        0.92, 0.73, \"Shared features\", va=\"center\", ha=\"left\", rotation=90, fontsize=10\n",
    "    )\n",
    "    # For private features (row 1): center between middle and bottom of plots\n",
    "    fig.text(\n",
    "        0.92, 0.43, \"Private features\", va=\"center\", ha=\"left\", rotation=90, fontsize=10\n",
    "    )\n",
    "\n",
    "    # Create custom legends in row 2\n",
    "    # Left legend: Task (vertical layout to fit width constraint)\n",
    "    ax20.axis(\"off\")\n",
    "    task_labels = np.unique(y_task_test_filtered.ravel())\n",
    "    task_patches = [\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"w\",\n",
    "            markerfacecolor=task_colors[i],\n",
    "            markersize=8,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "        for i in range(len(task_labels))\n",
    "    ]\n",
    "    legend_task = ax20.legend(\n",
    "        task_patches,\n",
    "        [f\"Class {int(label)}\" for label in task_labels],\n",
    "        title=\"Task\",\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 0.8),\n",
    "        frameon=True,\n",
    "        ncol=1,  # Vertical layout\n",
    "    )\n",
    "\n",
    "    # Right legend: Machine (vertical layout to fit width constraint)\n",
    "    ax21.axis(\"off\")\n",
    "    machine_labels = np.unique(y_domains_test_filtered[:, 0])\n",
    "    machine_patches = [\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"w\",\n",
    "            markerfacecolor=machine_colors[int(label)],\n",
    "            markersize=8,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "        for label in machine_labels\n",
    "    ]\n",
    "    legend_machine = ax21.legend(\n",
    "        machine_patches,\n",
    "        [f\"Instance {int(label) + 1}\" for label in machine_labels],\n",
    "        title=\"Affine domain\",\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 0.8),\n",
    "        frameon=True,\n",
    "        ncol=1,  # Vertical layout\n",
    "    )\n",
    "\n",
    "    plt.savefig(\"../outputs/disae2_dataB_shared_private_pca.pdf\", dpi=350)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Orthogonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check orthogonality between shared and private\n",
    "shared_private_corr = np.corrcoef(\n",
    "    np.concatenate([shared_test, private_test], axis=1).T\n",
    ")[: shared_test.shape[1], shared_test.shape[1] :]\n",
    "\n",
    "plt.figure(figsize=(2.2, 2.2))\n",
    "sns.heatmap(\n",
    "    shared_private_corr,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    cbar_kws={\"label\": \"Correlation\"},\n",
    ")\n",
    "plt.title(\"Shared-Private Feature Correlation\\n(Should be close to 0)\")\n",
    "plt.xlabel(\"Private Feature Index\")\n",
    "plt.ylabel(\"Shared Feature Index\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean absolute correlation: {np.abs(shared_private_corr).mean():.4f}\")\n",
    "print(f\"Max absolute correlation: {np.abs(shared_private_corr).max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reconstruction Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction\n",
    "X_reconstructed = model.reconstruct(X_test)\n",
    "reconstruction_mse = np.mean((X_test - X_reconstructed) ** 2)\n",
    "\n",
    "print(\"Reconstruction Quality:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Overall MSE: {reconstruction_mse:.6f}\")\n",
    "\n",
    "# Per-feature reconstruction error\n",
    "per_feature_mse = np.mean((X_test - X_reconstructed) ** 2, axis=0)\n",
    "\n",
    "plt.figure(figsize=(4.5, 2.2))\n",
    "plt.bar(range(len(per_feature_mse)), per_feature_mse, alpha=0.7)\n",
    "plt.axhline(\n",
    "    per_feature_mse.mean(),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean: {per_feature_mse.mean():.6f}\",\n",
    ")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Per-Feature Reconstruction Error\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model_path = \"disae2_data_B.pkl\"\n",
    "model.save(model_path)\n",
    "print(f\"✓ Model saved to {model_path}\")\n",
    "\n",
    "# Verify loading\n",
    "loaded_model = DisAE.load(model_path)\n",
    "y_pred_loaded = loaded_model.predict_tasks(X_test[:10])[0]\n",
    "print(f\"✓ Model loaded and verified successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bloodcounts_sysmex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
