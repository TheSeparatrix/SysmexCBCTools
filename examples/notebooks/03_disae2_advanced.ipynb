{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dis-AE 2: Advanced Usage\n",
    "\n",
    "This notebook covers advanced topics:\n",
    "1. Hyperparameter tuning and loss weight selection\n",
    "2. Model persistence and reuse\n",
    "3. Using embeddings for downstream tasks\n",
    "4. Analyzing learned representations\n",
    "5. Best practices and troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sysmexcbctools.disae2.disae2 import DisAE\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# PDF-compatible fonts\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "\n",
    "# Scientific plot style\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use([\"science\", \"nature\"])\n",
    "\n",
    "# Colourblind-friendly palette\n",
    "SEABORN_PALETTE = \"colorblind\"\n",
    "seaborn_colors = sns.color_palette(SEABORN_PALETTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n",
    "\n",
    "We'll use data_B.csv for these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/data_B.csv\")\n",
    "\n",
    "# Extract features and labels\n",
    "X = df[[str(i) for i in range(32)]].values\n",
    "y_task = df[\"ClassCategory_0\"].values.reshape(-1, 1)\n",
    "y_domains = df[[\"Machine\", \"vendelay_binned\", \"studytime_binned\"]].values.astype(int)\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data, this time let's keep all domains in train and test set.\n",
    "X_train, X_test, y_task_train, y_task_test, y_domains_train, y_domains_test = (\n",
    "    train_test_split(\n",
    "        X, y_task, y_domains, test_size=0.2, stratify=y_domains[:, 0], random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "X_train, X_val, y_task_train, y_task_val, y_domains_train, y_domains_val = (\n",
    "    train_test_split(\n",
    "        X_train,\n",
    "        y_task_train,\n",
    "        y_domains_train,\n",
    "        test_size=0.2,\n",
    "        stratify=y_domains_train[:, 0],\n",
    "        random_state=42,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Train: {X_train.shape[0]:,}, Val: {X_val.shape[0]:,}, Test: {X_test.shape[0]:,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter Tuning: Loss Weights\n",
    "\n",
    "The three key loss weights control the tradeoff between objectives:\n",
    "- `reconstruction_weight`: Higher = better reconstruction, may preserve more domain info\n",
    "- `adversarial_weight`: Higher = stronger domain invariance, may hurt task performance\n",
    "- `orthogonality_weight`: Higher = more separation between shared/private features\n",
    "\n",
    "### Experiment: Varying Adversarial Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different adversarial weights\n",
    "adv_weights = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "results = []\n",
    "\n",
    "if torch.cuda.is_available():  # NVIDIA GPU preferred\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():  # Apple Silicon GPU if running on Mac\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"  # CPU fallback\n",
    "\n",
    "for adv_weight in adv_weights:\n",
    "    print(f\"\\nTraining with adversarial_weight={adv_weight}...\")\n",
    "\n",
    "    model = DisAE(\n",
    "        input_dim=32,\n",
    "        latent_dim=16,\n",
    "        num_tasks=[2],\n",
    "        num_domains=[5, 10, 10],\n",
    "        hidden_dims=[64, 32],\n",
    "        reconstruction_weight=0.1,\n",
    "        adversarial_weight=adv_weight,  # Vary this\n",
    "        orthogonality_weight=0.1,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=256,\n",
    "        device=device,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_task_train,\n",
    "        y_domains_train,\n",
    "        X_val=X_val,\n",
    "        y_tasks_val=y_task_val,\n",
    "        y_domains_val=y_domains_val,\n",
    "        max_epochs=50,\n",
    "        early_stopping_patience=10,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict_tasks(X_test)[0]\n",
    "    task_acc = accuracy_score(y_task_test, y_pred)\n",
    "\n",
    "    d_pred = model.predict_domains(X_test)\n",
    "    domain_acc = np.mean(\n",
    "        [accuracy_score(y_domains_test[:, i], d_pred[i]) for i in range(3)]\n",
    "    )\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"adversarial_weight\": adv_weight,\n",
    "            \"task_accuracy\": task_acc,\n",
    "            \"domain_accuracy\": domain_acc,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"  Task accuracy: {task_acc:.4f}\")\n",
    "    print(f\"  Domain accuracy: {domain_acc:.4f} (lower is better)\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise tradeoff\n",
    "fig, axes = plt.subplots(1, 2, figsize=(4.5, 2.2))\n",
    "\n",
    "# Task accuracy vs adversarial weight\n",
    "axes[0].plot(\n",
    "    results_df[\"adversarial_weight\"],\n",
    "    results_df[\"task_accuracy\"],\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    ")\n",
    "axes[0].set_xlabel(\"Adversarial Weight\")\n",
    "axes[0].set_ylabel(\"Task Accuracy\")\n",
    "axes[0].set_title(\"Task Performance vs Adversarial Weight\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Domain accuracy vs adversarial weight\n",
    "axes[1].plot(\n",
    "    results_df[\"adversarial_weight\"],\n",
    "    results_df[\"domain_accuracy\"],\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    color=\"coral\",\n",
    ")\n",
    "axes[1].axhline(\n",
    "    1.0 / 5, color=\"red\", linestyle=\"--\", label=\"Random (Machine)\", alpha=0.5\n",
    ")\n",
    "axes[1].axhline(\n",
    "    1.0 / 10, color=\"orange\", linestyle=\"--\", label=\"Random (Delay/Time)\", alpha=0.5\n",
    ")\n",
    "axes[1].set_xlabel(\"Adversarial Weight\")\n",
    "axes[1].set_ylabel(\"Domain Accuracy (Lower=Better)\")\n",
    "axes[1].set_title(\"Domain Invariance vs Adversarial Weight\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"\\n✓ Higher adversarial weight → Better domain invariance but may hurt task accuracy\"\n",
    ")\n",
    "print(\"✓ Choose weight that balances both objectives for your use case\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Latent Dimension Selection\n",
    "\n",
    "**Important**: Due to the orthogonality loss implementation (element-wise dot product), `shared_dim` must equal `private_dim`.\n",
    "\n",
    "We can experiment with different total latent dimensions (always split equally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different total latent dimensions (always equal split)\n",
    "latent_dims = [8, 16, 32, 64]\n",
    "dim_results = []\n",
    "\n",
    "for latent_dim in latent_dims:\n",
    "    shared_dim = latent_dim // 2\n",
    "    private_dim = latent_dim // 2\n",
    "\n",
    "    print(\n",
    "        f\"\\nTraining with latent_dim={latent_dim} (shared={shared_dim}, private={private_dim})...\"\n",
    "    )\n",
    "\n",
    "    model = DisAE(\n",
    "        input_dim=32,\n",
    "        latent_dim=latent_dim,  # Automatically splits equally\n",
    "        num_tasks=[2],\n",
    "        num_domains=[5, 10, 10],\n",
    "        hidden_dims=[64, 32],\n",
    "        reconstruction_weight=0.1,\n",
    "        adversarial_weight=1.0,\n",
    "        orthogonality_weight=0.1,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=256,\n",
    "        device=device,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_task_train,\n",
    "        y_domains_train,\n",
    "        X_val=X_val,\n",
    "        y_tasks_val=y_task_val,\n",
    "        y_domains_val=y_domains_val,\n",
    "        max_epochs=50,\n",
    "        early_stopping_patience=10,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict_tasks(X_test)[0]\n",
    "    task_acc = accuracy_score(y_task_test, y_pred)\n",
    "\n",
    "    X_recon = model.reconstruct(X_test)\n",
    "    recon_mse = np.mean((X_test - X_recon) ** 2)\n",
    "\n",
    "    dim_results.append(\n",
    "        {\n",
    "            \"latent_dim\": latent_dim,\n",
    "            \"shared_dim\": shared_dim,\n",
    "            \"private_dim\": private_dim,\n",
    "            \"task_accuracy\": task_acc,\n",
    "            \"reconstruction_mse\": recon_mse,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"  Task accuracy: {task_acc:.4f}\")\n",
    "    print(f\"  Reconstruction MSE: {recon_mse:.6f}\")\n",
    "\n",
    "dim_results_df = pd.DataFrame(dim_results)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(dim_results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n✓ Larger latent_dim → More capacity for both task and domain information\")\n",
    "print(\"✓ Too small → May not capture sufficient information\")\n",
    "print(\"✓ Too large → Risk of overfitting, slower training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Persistence: Save, Load, and Reuse\n",
    "\n",
    "Train once, use many times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model\n",
    "print(\"Training model...\")\n",
    "model = DisAE(\n",
    "    input_dim=32,\n",
    "    latent_dim=16,\n",
    "    num_tasks=[2],\n",
    "    num_domains=[5, 10, 10],\n",
    "    hidden_dims=[64, 32],\n",
    "    reconstruction_weight=0.1,\n",
    "    adversarial_weight=1.0,\n",
    "    orthogonality_weight=0.1,\n",
    "    learning_rate=0.01,\n",
    "    batch_size=256,\n",
    "    device=device,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_task_train,\n",
    "    y_domains_train,\n",
    "    X_val=X_val,\n",
    "    y_tasks_val=y_task_val,\n",
    "    y_domains_val=y_domains_val,\n",
    "    max_epochs=50,\n",
    "    early_stopping_patience=10,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\"✓ Model trained\")\n",
    "\n",
    "# Save model\n",
    "model_path = \"disae2_trained_model.pkl\"\n",
    "model.save(model_path)\n",
    "print(f\"✓ Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model in a \"fresh session\"\n",
    "print(\"Loading model from disk...\")\n",
    "loaded_model = DisAE.load(model_path)\n",
    "print(\"✓ Model loaded successfully\")\n",
    "\n",
    "# Verify it works\n",
    "y_pred_original = model.predict_tasks(X_test)[0]\n",
    "y_pred_loaded = loaded_model.predict_tasks(X_test)[0]\n",
    "\n",
    "assert np.array_equal(y_pred_original, y_pred_loaded), \"Predictions don't match!\"\n",
    "print(\"✓ Loaded model produces identical predictions\")\n",
    "\n",
    "# Check model parameters\n",
    "print(f\"\\nLoaded model configuration:\")\n",
    "print(f\"  Input dim: {loaded_model.input_dim}\")\n",
    "print(f\"  Shared dim: {loaded_model.shared_dim}\")\n",
    "print(f\"  Private dim: {loaded_model.private_dim}\")\n",
    "print(f\"  Num tasks: {loaded_model.num_tasks}\")\n",
    "print(f\"  Num domains: {loaded_model.num_domains}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using Embeddings for Downstream Tasks\n",
    "\n",
    "Extract shared features and use them as input to other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings\n",
    "shared_train = loaded_model.embed(X_train, private=False)\n",
    "shared_test = loaded_model.embed(X_test, private=False)\n",
    "\n",
    "print(f\"Extracted shared features:\")\n",
    "print(f\"  Train: {shared_train.shape}\")\n",
    "print(f\"  Test: {shared_test.shape}\")\n",
    "\n",
    "# Use shared features for classification\n",
    "print(\"\\nTraining logistic regression on shared features...\")\n",
    "lr_on_shared = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_on_shared.fit(shared_train, y_task_train.ravel())\n",
    "\n",
    "y_pred_shared = lr_on_shared.predict(shared_test)\n",
    "acc_shared = accuracy_score(y_task_test, y_pred_shared)\n",
    "\n",
    "# Compare with logistic regression on original features\n",
    "lr_on_original = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_on_original.fit(X_train, y_task_train.ravel())\n",
    "\n",
    "y_pred_original = lr_on_original.predict(X_test)\n",
    "acc_original = accuracy_score(y_task_test, y_pred_original)\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  LR on shared features: {acc_shared:.4f}\")\n",
    "print(f\"  LR on original features: {acc_original:.4f}\")\n",
    "print(f\"\\n✓ Shared features maintain task information while being domain-invariant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyzing What the Model Learned\n",
    "\n",
    "### Feature Importance via Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which features are well-reconstructed\n",
    "X_recon = loaded_model.reconstruct(X_test)\n",
    "per_feature_mse = np.mean((X_test - X_recon) ** 2, axis=0)\n",
    "\n",
    "# Plot feature reconstruction error\n",
    "fig, axes = plt.subplots(1, 2, figsize=(4.5, 2.2))\n",
    "\n",
    "axes[0].bar(range(32), per_feature_mse)\n",
    "axes[0].set_xlabel(\"Feature Index\")\n",
    "axes[0].set_ylabel(\"Reconstruction MSE\")\n",
    "axes[0].set_title(\"Per-Feature Reconstruction Error\")\n",
    "axes[0].axhline(per_feature_mse.mean(), color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Sort and show top 10 worst-reconstructed features\n",
    "worst_features = np.argsort(per_feature_mse)[-10:]\n",
    "axes[1].barh(range(10), per_feature_mse[worst_features])\n",
    "axes[1].set_yticks(range(10))\n",
    "axes[1].set_yticklabels([f\"Feature {i}\" for i in worst_features])\n",
    "axes[1].set_xlabel(\"Reconstruction MSE\")\n",
    "axes[1].set_title(\"10 Worst-Reconstructed Features\")\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"✓ High reconstruction error may indicate features with high domain-specific variance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing What Shared Features Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shared features\n",
    "shared_test = loaded_model.embed(X_test, private=False)\n",
    "\n",
    "# PCA to 2D\n",
    "pca = PCA(n_components=2)\n",
    "shared_2d = pca.fit_transform(shared_test)\n",
    "\n",
    "print(f\"PCA explained variance: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "# Plot with different colorings\n",
    "with plt.style.context([\"science\", \"nature\", \"scatter\"]):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(6.6, 2.2))\n",
    "\n",
    "    # By task\n",
    "    scatter1 = axes[0].scatter(\n",
    "        shared_2d[:, 0],\n",
    "        shared_2d[:, 1],\n",
    "        c=y_task_test.ravel(),\n",
    "        cmap=\"viridis\",\n",
    "        s=5,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    axes[0].set_title(\"Shared Features by Task\")\n",
    "    axes[0].set_xlabel(\"PC1\")\n",
    "    axes[0].set_ylabel(\"PC2\")\n",
    "    plt.colorbar(scatter1, ax=axes[0])\n",
    "\n",
    "    # By machine\n",
    "    scatter2 = axes[1].scatter(\n",
    "        shared_2d[:, 0],\n",
    "        shared_2d[:, 1],\n",
    "        c=y_domains_test[:, 0],\n",
    "        cmap=\"Set1\",\n",
    "        s=5,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    axes[1].set_title(\"Shared Features by Machine\")\n",
    "    axes[1].set_xlabel(\"PC1\")\n",
    "    axes[1].set_ylabel(\"PC2\")\n",
    "    plt.colorbar(scatter2, ax=axes[1])\n",
    "\n",
    "    # By study time\n",
    "    scatter3 = axes[2].scatter(\n",
    "        shared_2d[:, 0],\n",
    "        shared_2d[:, 1],\n",
    "        c=y_domains_test[:, 2],\n",
    "        cmap=\"plasma\",\n",
    "        s=5,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    axes[2].set_title(\"Shared Features by Study Time\")\n",
    "    axes[2].set_xlabel(\"PC1\")\n",
    "    axes[2].set_ylabel(\"PC2\")\n",
    "    plt.colorbar(scatter3, ax=axes[2])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"✓ Left plot should show separation (task-relevant)\")\n",
    "print(\"✓ Middle/right plots should show mixing (domain-invariant)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best Practices and Tips\n",
    "\n",
    "### Important Constraint\n",
    "\n",
    "⚠️ **shared_dim must equal private_dim**: The orthogonality loss uses element-wise dot product, requiring equal dimensions. Use `latent_dim` parameter for automatic equal splitting.\n",
    "\n",
    "### Loss Weight Guidelines\n",
    "\n",
    "| Weight | Low (0.01-0.1) | Medium (0.1-1.0) | High (1.0-10.0) |\n",
    "|--------|---------------|------------------|----------------|\n",
    "| **Reconstruction** | Domain invariance priority | Balanced | Reconstruction priority |\n",
    "| **Adversarial** | Task accuracy priority | Balanced | Strong domain invariance |\n",
    "| **Orthogonality** | Allow feature mixing | Balanced | Strict feature separation |\n",
    "\n",
    "### When to Use Dis-AE 2\n",
    "\n",
    "✓ Multiple domain factors (machines, batches, sites)  \n",
    "✓ Domain shift is a concern  \n",
    "✓ Need interpretable features (shared = task, private = domain)  \n",
    "✓ Want to understand domain effects  \n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "**Poor task accuracy:**\n",
    "- Reduce `adversarial_weight`\n",
    "- Increase `latent_dim` (more capacity)\n",
    "- Train longer (increase `max_epochs`)\n",
    "\n",
    "**Domain information leaking:**\n",
    "- Increase `adversarial_weight`\n",
    "- Increase `orthogonality_weight`\n",
    "- Use more discriminator updates (`d_steps_per_g_step`)\n",
    "\n",
    "**Poor reconstruction:**\n",
    "- Increase `reconstruction_weight`\n",
    "- Increase `latent_dim` (more capacity)\n",
    "- Check if data normalization is appropriate\n",
    "\n",
    "### Data Preparation Checklist\n",
    "\n",
    "1. ✓ Normalize/standardize features\n",
    "2. ✓ Encode labels as integers (0, 1, 2, ...)\n",
    "3. ✓ Use train/val split for early stopping\n",
    "4. ✓ Stratify by domain when splitting\n",
    "5. ✓ Check for class imbalance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bloodcounts_sysmex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
