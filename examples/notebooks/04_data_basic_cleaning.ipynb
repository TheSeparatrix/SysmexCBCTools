{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Module: Basic XN_SAMPLE Cleaning\n",
    "\n",
    "This notebook demonstrates basic usage of the `XNSampleProcessor` for cleaning and standardizing Sysmex XN_SAMPLE.csv files.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `XNSampleProcessor` provides a simple, pandas-like interface for processing raw Sysmex XN_SAMPLE data exported from decrypted .116 files. It handles:\n",
    "\n",
    "- Removing duplicate rows and technical samples (QC, calibration)\n",
    "- Encoding flags and indicators\n",
    "- Detecting and handling clotted samples\n",
    "- Managing multiple measurements per sample\n",
    "- Converting data types and cleaning non-numeric values\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path to import sysmexcbctools\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sysmexcbctools.data import XNSampleProcessor\n",
    "\n",
    "# For nice display\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Usage\n",
    "\n",
    "The simplest way to use the processor is to load and clean a single XN_SAMPLE.csv file.\n",
    "\n",
    "### Specifying Data Paths\n",
    "\n",
    "You have two options for specifying the path to your data:\n",
    "\n",
    "**Option 1: Use YAML configuration** (recommended for managing multiple datasets)\n",
    "- Edit `sysmexcbctools/transfer/config/data_paths.yaml` to include your data paths\n",
    "- The code below will automatically load from the config\n",
    "- This keeps paths centralized and makes notebooks portable\n",
    "\n",
    "**Option 2: Manual path specification** (simple fallback)\n",
    "- If the config file is not available or doesn't contain your dataset\n",
    "- The code will fall back to a manual path that you can edit\n",
    "- Just update the `data_path` variable with your file location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your XN_SAMPLE.csv file\n",
    "# Option 1: Use the config loader (if you have the data_paths.yaml configured)\n",
    "try:\n",
    "    from sysmexcbctools.transfer.config.config_loader import ConfigLoader\n",
    "\n",
    "    config_loader = ConfigLoader(\n",
    "        config_file=str(\n",
    "            project_root / \"sysmexcbctools/transfer/config/data_paths.yaml\"\n",
    "        ),\n",
    "        environment=\"production\",\n",
    "    )\n",
    "\n",
    "    # Get the raw data directory for INTERVAL dataset 36\n",
    "    dataset_dir = config_loader.get_dataset_path(category=\"raw\", dataset=\"interval_36\")\n",
    "    data_path = dataset_dir / \"XN_SAMPLE.csv\"\n",
    "\n",
    "    print(f\"✓ Loaded path from config: {data_path}\")\n",
    "\n",
    "except (FileNotFoundError, ValueError, KeyError) as e:\n",
    "    print(f\"⚠ Could not load from config: {e}\")\n",
    "    print(\"  Falling back to manual path specification...\")\n",
    "\n",
    "    # Option 2: Manually specify your data path\n",
    "    # EDIT THIS PATH to point to your XN_SAMPLE.csv file:\n",
    "    data_path = Path(\"/path/to/your/XN_SAMPLE.csv\")\n",
    "\n",
    "    print(f\"\\n  Please edit this cell and set data_path to your file location.\")\n",
    "    print(f\"  Current (placeholder) path: {data_path}\")\n",
    "\n",
    "print(f\"\\nFile exists: {data_path.exists()}\")\n",
    "if data_path.exists():\n",
    "    print(f\"File size: {data_path.stat().st_size / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processor with default settings\n",
    "processor = XNSampleProcessor(\n",
    "    verbose=1,  # Show info-level logging\n",
    "    log_to_file=True,  # Also save diagnostics and logs to file (optional)\n",
    ")\n",
    "\n",
    "# Process the file (returns cleaned DataFrame)\n",
    "df_clean = processor.process_files(\n",
    "    input_files=str(data_path),\n",
    "    dataset_name=\"example\",\n",
    "    save_output=False,  # Don't save to disk (default)\n",
    ")\n",
    "\n",
    "print(f\"\\nCleaned dataframe shape: {df_clean.shape}\")\n",
    "print(f\"Unique samples: {df_clean['Sample No.'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspect Before/After Statistics\n",
    "\n",
    "Let's compare the raw and cleaned data to see what was removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data for comparison\n",
    "df_raw = pd.read_csv(data_path, encoding=\"ISO-8859-1\", low_memory=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BEFORE CLEANING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {df_raw.shape}\")\n",
    "print(f\"Columns: {df_raw.shape[1]}\")\n",
    "print(f\"Rows: {df_raw.shape[0]}\")\n",
    "print(f\"Unique samples: {df_raw['Sample No.'].nunique()}\")\n",
    "print(f\"Sample number prefixes (first 100):\")\n",
    "print(df_raw[\"Sample No.\"].str[:3].value_counts().head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"AFTER CLEANING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {df_clean.shape}\")\n",
    "print(f\"Columns: {df_clean.shape[1]}\")\n",
    "print(f\"Rows: {df_clean.shape[0]}\")\n",
    "print(f\"Unique samples: {df_clean['Sample No.'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Standard FBC Features\n",
    "\n",
    "Let's look at the standard full blood count (FBC) parameters that are preserved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard FBC parameters\n",
    "fbc_params = [\n",
    "    \"WBC(10^3/uL)\",\n",
    "    \"RBC(10^6/uL)\",\n",
    "    \"HGB(g/dL)\",\n",
    "    \"HCT(%)\",\n",
    "    \"PLT(10^3/uL)\",\n",
    "    \"MCV(fL)\",\n",
    "    \"MCH(pg)\",\n",
    "    \"MCHC(g/dL)\",\n",
    "    \"NEUT#(10^3/uL)\",\n",
    "    \"LYMPH#(10^3/uL)\",\n",
    "    \"MONO#(10^3/uL)\",\n",
    "    \"EO#(10^3/uL)\",\n",
    "    \"BASO#(10^3/uL)\",\n",
    "]\n",
    "\n",
    "# Check which are available\n",
    "available_fbc = [p for p in fbc_params if p in df_clean.columns]\n",
    "print(f\"Available FBC parameters ({len(available_fbc)}/{len(fbc_params)}):\")\n",
    "print(available_fbc)\n",
    "\n",
    "# Display summary statistics\n",
    "if available_fbc:\n",
    "    print(\"\\nSummary statistics for FBC parameters:\")\n",
    "    display(df_clean[available_fbc].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions of key FBC parameters\n",
    "if len(available_fbc) >= 4:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    fig.suptitle(\"Distribution of Key FBC Parameters\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    for ax, param in zip(axes.flat, available_fbc[:4]):\n",
    "        data = df_clean[param].dropna()\n",
    "        ax.hist(data, bins=50, alpha=0.7, edgecolor=\"black\")\n",
    "        ax.set_xlabel(param)\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "        ax.set_title(\n",
    "            f\"{param}\\n(n={len(data):,}, {len(data)/len(df_clean)*100:.1f}% non-null)\"\n",
    "        )\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough FBC parameters available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Review Quality Control Flags\n",
    "\n",
    "The processor encodes various quality control flags as binary indicators. Let's examine them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find flag columns\n",
    "flag_cols = [\n",
    "    col\n",
    "    for col in df_clean.columns\n",
    "    if col.startswith(\"IP \")\n",
    "    or col.startswith(\"Error\")\n",
    "    or col.startswith(\"Positive\")\n",
    "    or col.endswith(\"Abnormal\")\n",
    "    or col.endswith(\"Suspect\")\n",
    "]\n",
    "\n",
    "print(f\"Found {len(flag_cols)} flag columns:\")\n",
    "print(flag_cols[:20])  # Show first 20\n",
    "\n",
    "if flag_cols:\n",
    "    # Count how many samples have each flag\n",
    "    flag_counts = df_clean[flag_cols].sum().sort_values(ascending=False)\n",
    "\n",
    "    print(\"\\nMost common flags (top 10):\")\n",
    "    print(flag_counts.head(10))\n",
    "\n",
    "    # Visualize most common flags\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    flag_counts.head(15).plot(kind=\"barh\")\n",
    "    plt.xlabel(\"Number of samples\")\n",
    "    plt.title(\"Most Common Quality Control Flags\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Missing Data Analysis\n",
    "\n",
    "Understanding missingness patterns is important for downstream analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missingness for key FBC parameters\n",
    "if available_fbc:\n",
    "    missing_fbc = df_clean[available_fbc].isnull().sum() / len(df_clean) * 100\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    missing_fbc.sort_values().plot(kind=\"barh\", color=\"coral\")\n",
    "    plt.xlabel(\"Missing (%)\")\n",
    "    plt.title(\"Missingness in Standard FBC Parameters\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Types and Memory Usage\n",
    "\n",
    "The processor automatically converts columns to appropriate numeric types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"Data types summary:\")\n",
    "print(df_clean.dtypes.value_counts())\n",
    "\n",
    "# Memory usage\n",
    "memory_mb = df_clean.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"\\nMemory usage: {memory_mb:.2f} MB\")\n",
    "\n",
    "# Show non-numeric columns (if any)\n",
    "non_numeric = df_clean.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "print(f\"\\nNon-numeric columns ({len(non_numeric)}):\")\n",
    "print(non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Diagnostic Files\n",
    "\n",
    "The processor generates diagnostic files for samples that need manual review (e.g., multiple measurements with discrepancies):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any diagnostic files were created\n",
    "diagnostic_files = processor.get_diagnostic_files()\n",
    "\n",
    "if diagnostic_files:\n",
    "    print(\"Diagnostic files generated:\")\n",
    "    for file_type, path in diagnostic_files.items():\n",
    "        print(f\"  {file_type}: {path}\")\n",
    "        if Path(path).exists():\n",
    "            size_kb = Path(path).stat().st_size / 1024\n",
    "            print(f\"    Size: {size_kb:.1f} KB\")\n",
    "else:\n",
    "    print(\"No diagnostic files were generated (all samples passed quality checks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Saving Results\n",
    "\n",
    "If you want to save the processed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Save manually\n",
    "output_path = project_root / \"examples\" / \"outputs\" / \"cleaned_example.csv\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Saving to: {output_path}\")\n",
    "# Uncomment to actually save:\n",
    "# df_clean.to_csv(output_path, index=False)\n",
    "# print(f\"Saved! File size: {output_path.stat().st_size / 1024**2:.1f} MB\")\n",
    "\n",
    "print(\"(Uncomment code above to actually save the file)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Use processor to save (with automatic timestamping)\n",
    "processor2 = XNSampleProcessor(\n",
    "    output_dir=str(project_root / \"examples\" / \"outputs\"), verbose=1\n",
    ")\n",
    "\n",
    "# This will automatically save with timestamp\n",
    "# Uncomment to actually process and save:\n",
    "# df_clean2 = processor2.process_files(\n",
    "#     input_files=str(data_path),\n",
    "#     dataset_name=\"example\",\n",
    "#     save_output=True  # This enables automatic saving\n",
    "# )\n",
    "\n",
    "print(\"(Uncomment code above to process and automatically save)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated:\n",
    "\n",
    "1. ✅ **Basic usage** - Loading and cleaning XN_SAMPLE.csv files with minimal code\n",
    "2. ✅ **Before/after comparison** - Understanding what data is removed and why\n",
    "3. ✅ **FBC parameters** - Exploring standard full blood count measurements\n",
    "4. ✅ **Quality flags** - Reviewing encoded quality control indicators\n",
    "5. ✅ **Missing data** - Analyzing missingness patterns\n",
    "6. ✅ **Data types** - Checking automatic type conversion\n",
    "7. ✅ **Diagnostic files** - Accessing samples flagged for manual review\n",
    "8. ✅ **Saving results** - Multiple options for output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bloodcounts_sysmex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
