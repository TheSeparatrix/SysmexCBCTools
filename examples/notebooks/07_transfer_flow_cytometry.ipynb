{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Cytometry Alignment with FlowTransformer\n",
    "\n",
    "This notebook demonstrates how to align Sysmex flow cytometry data (RET, WDF, WNR, PLTF channels) between different analysers using the `FlowTransformer` API.\n",
    "\n",
    "## ⚠️ Important: Memory Requirements\n",
    "\n",
    "**This notebook requires significant computational resources:**\n",
    "- Flow cytometry data involves millions of data points\n",
    "- GMM fitting with many components on large datasets is memory-intensive\n",
    "- **Recommended**: Run on system with sufficient memory\n",
    "- **Laptop users**: May experience kernel crashes or slow performance\n",
    "\n",
    "**For testing purposes**, consider:\n",
    "- Reducing `n_components`\n",
    "- Setting `max_samples=100000` to limit data size\n",
    "- Using fewer input files for initial testing\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `FlowTransformer` uses Gaussian Mixture Models (GMM) combined with Optimal Transport (OT) to align flow cytometry distributions across different analysers. This is useful when:\n",
    "\n",
    "- Combining data from multiple analyser machines\n",
    "- Correcting batch effects between analyser units  \n",
    "- Training machine learning models on data from one analyser and applying to another\n",
    "\n",
    "## Method\n",
    "\n",
    "1. **Fit GMMs**: Gaussian mixture models are fit to both source and target distributions\n",
    "2. **Compute transport**: Optimal transport plan computed between GMM components\n",
    "3. **Transform**: Individual data points are transformed using the transport map\n",
    "4. **Validate**: Compare transformed distribution to target using Wasserstein distance\n",
    "\n",
    "\n",
    "The math behind the method is from:\n",
    "Julie Delon and Agnès Desolneux. A Wasserstein-Type Distance in the Space of 13\n",
    "Gaussian Mixture Models. SIAM Journal on Imaging Sciences, 13(2):936–970, 14\n",
    "January 2020. doi: 10.1137/19M1301047. URL https://epubs.siam.org/doi/abs/10. 15\n",
    "1137/19M1301047. Publisher: Society for Industrial and Applied Mathematics.\n",
    "\n",
    "\n",
    "### ⚠️ Important:  This notebook uses data from the INTERVAL and STRIDES blood donor studies which we have available in Cambridge. Users will have to load their own Sysmex flow cytometry data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Import from sysmexcbctools.transfer\n",
    "from sysmexcbctools.transfer.sysmexalign import FlowTransformer\n",
    "from sysmexcbctools.transfer.config import load_config\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "\n",
    "\n",
    "import scienceplots\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use([\"science\", \"nature\"])\n",
    "\n",
    "SEABORN_PALETTE = \"colorblind\"\n",
    "seaborn_colors = sns.color_palette(SEABORN_PALETTE)\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data Paths\n",
    "\n",
    "Flow cytometry data is stored in `.116.csv` files with the format:\n",
    "```\n",
    "CHANNEL_[analyserID][...][YYYYMMDD_HHMMSS][SampleNumber].116.csv\n",
    "```\n",
    "\n",
    "For this example, we'll use **real data from two different Sysmex analysers**:\n",
    "- **Source**: STRIDES study data\n",
    "- **Target**: INTERVAL study (analyser XN-10^11036)\n",
    "\n",
    "We'll work with the **RET (reticulocyte)** channel as the primary example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration to get data paths\n",
    "# The config file contains paths to RDS storage for different datasets\n",
    "\n",
    "# Load data paths configuration\n",
    "config = load_config(str(\"../../sysmexcbctools/transfer/config/data_paths.yaml\"))\n",
    "\n",
    "# Get dataset paths for two different analysers\n",
    "# Source: STRIDES merged data\n",
    "# Target: INTERVAL analyser XN-10^11036\n",
    "SOURCE_DIR = config[\"datasets\"][\"raw\"][\"strides_merged\"] + \"/SCT\"\n",
    "TARGET_DIR = config[\"datasets\"][\"raw\"][\"interval_36\"] + \"/SCT\"\n",
    "\n",
    "# Also load sample numbers for filtering (optional but recommended)\n",
    "# These .npy files contain centile sample numbers that represent the population well\n",
    "source_samples_file = config[\"files\"][\"centile_samples\"][\"strides\"]\n",
    "target_samples_file = config[\"files\"][\"centile_samples\"][\"interval_baseline_36\"]\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR = \"../outputs/flow_transformed/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Data Configuration Loaded:\")\n",
    "print(f\"Source directory: {SOURCE_DIR}\")\n",
    "print(f\"Target directory: {TARGET_DIR}\")\n",
    "print(f\"Source samples file: {source_samples_file}\")\n",
    "print(f\"Target samples file: {target_samples_file}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample numbers for filtering (recommended for large datasets)\n",
    "# These files contain sample numbers that represent population centiles well\n",
    "source_sample_nos = np.load(source_samples_file, allow_pickle=True)\n",
    "target_sample_nos = np.load(target_samples_file, allow_pickle=True)\n",
    "\n",
    "print(f\"\\nSample filtering:\")\n",
    "print(f\"  Source samples: {len(source_sample_nos):,} centile samples\")\n",
    "print(f\"  Target samples: {len(target_sample_nos):,} centile samples\")\n",
    "\n",
    "# Get all RET files from both directories\n",
    "# Note: This may take a moment for large directories on RDS\n",
    "print(\"\\nScanning for RET channel files...\")\n",
    "source_files_all = sorted(Path(SOURCE_DIR).glob(\"RET*.csv\"))\n",
    "target_files_all = sorted(Path(TARGET_DIR).glob(\"RET*.csv\"))\n",
    "\n",
    "print(f\"  Total source RET files: {len(source_files_all):,}\")\n",
    "print(f\"  Total target RET files: {len(target_files_all):,}\")\n",
    "\n",
    "# For initial testing, we'll use just the centile samples\n",
    "# This provides a representative subset without processing millions of cells\n",
    "USE_CENTILE_SAMPLES = True  # Set to False to use all files\n",
    "\n",
    "if USE_CENTILE_SAMPLES:\n",
    "    print(\"\\nUsing centile samples for efficient computation...\")\n",
    "    # Filter to only files matching centile sample numbers\n",
    "    # File format: RET_[analyser][...][date_time][sample_number].116.csv\n",
    "    # We'll match files by sample number (extract from filename)\n",
    "\n",
    "    def extract_sample_number(filepath):\n",
    "        \"\"\"Extract sample number from .116.csv filename\"\"\"\n",
    "        # Format: RET_[XN-20^14232][00-22_123][20211002_001515][      XXXXXX].116.csv\n",
    "        # Sample number is in the last bracketed section before .116.csv (XXXXXX)\n",
    "        import re\n",
    "\n",
    "        match = re.search(r\"\\[([^\\]]+)\\]\\.116\", str(filepath.name))\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        return None\n",
    "\n",
    "    # Filter files by sample numbers\n",
    "    source_files = [\n",
    "        f for f in source_files_all if extract_sample_number(f) in source_sample_nos\n",
    "    ]\n",
    "    target_files = [\n",
    "        f for f in target_files_all if extract_sample_number(f) in target_sample_nos\n",
    "    ]\n",
    "\n",
    "    print(f\"  Filtered source files: {len(source_files):,}\")\n",
    "    print(f\"  Filtered target files: {len(target_files):,}\")\n",
    "else:\n",
    "    source_files = source_files_all\n",
    "    target_files = target_files_all\n",
    "    print(\"\\nUsing all available files (may be memory-intensive)...\")\n",
    "\n",
    "# Show example filenames\n",
    "if len(source_files) > 0:\n",
    "    print(f\"\\nExample source file:\")\n",
    "    print(f\"  {source_files[0].name}\")\n",
    "if len(target_files) > 0:\n",
    "    print(f\"\\nExample target file:\")\n",
    "    print(f\"  {target_files[0].name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data\n",
    "\n",
    "**Why use centile samples?**\n",
    "- Flow cytometry files can be very large (millions of data points per sample)\n",
    "- Centile samples are pre-selected to represent the population distribution well (if you have QC samples available, that's even better)\n",
    "- This makes computation tractable while maintaining statistical validity\n",
    "- You can still use all samples by setting `USE_CENTILE_SAMPLES = False` above\n",
    "\n",
    "**What we're aligning:**\n",
    "- **Source**: STRIDES study (different analyser/lab/year)\n",
    "- **Target**: INTERVAL study baseline (analyser XN-10^11036)\n",
    "- **Goal**: Transform STRIDES data to match INTERVAL distribution\n",
    "\n",
    "This enables cross-study comparisons and pooling data from multiple analysers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Transformer\n",
    "\n",
    "Create a `FlowTransformer` for the RET channel with sensible defaults.\n",
    "\n",
    "**Note on `save_fitted_data` parameter:**\n",
    "- By default, the transformer does NOT save the downsampled data used for fitting (for privacy and memory reasons)\n",
    "- Set `save_fitted_data=True` to enable saving the data in `source_data_` and `target_data_` attributes\n",
    "- This is useful for visualization and validation (as shown below)\n",
    "- The saved data is the downsampled version (up to `max_samples`) after filtering out saturated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FlowTransformer(\n",
    "    channel=\"RET\",  # Channel to transform\n",
    "    n_components=64,  # Number of Gaussian components\n",
    "    covariance_type=\"full\",  # Full covariance matrices\n",
    "    transport_method=\"rand\",  # T_rand transport method\n",
    "    max_samples=1_000_000,  # Downsample if more samples\n",
    "    preserve_rare=False,  # Disable rare handling\n",
    "    omega_threshold=0.0,  # Don't filter target components\n",
    "    use_cascade_init=True,  # Use cascade initialisation (target GMM initialised from fitted source GMM)\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    random_state=42,  # For reproducibility\n",
    "    save_fitted_data=True,  # Save data used for fitting (for later visualization) -- this might not always be a good idea since can be very large or sensitive patient data\n",
    ")\n",
    "\n",
    "print(\"Transformer configuration:\")\n",
    "print(f\"  Channel: {transformer.channel}\")\n",
    "print(f\"  GMM components: {transformer.n_components}\")\n",
    "print(f\"  Use cascade init: {transformer.use_cascade_init}\")\n",
    "print(f\"  Rare threshold: {transformer.rare_threshold}\")\n",
    "print(f\"  Omega threshold: {transformer.omega_threshold}\")\n",
    "print(f\"  Save fitted data: {transformer.save_fitted_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit the Transformation\n",
    "\n",
    "Fit GMM models to both source and target distributions, then compute the optimal transport map.\n",
    "\n",
    "**Note**: This step can take several minutes depending on data size and number of components. The transformer will:\n",
    "1. Load and concatenate all source and target files\n",
    "2. Downsample if needed (to `max_samples`)\n",
    "3. Fit GMM models to both distributions\n",
    "4. Compute the optimal transport plan between GMM components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have data to work with\n",
    "if len(source_files) == 0 or len(target_files) == 0:\n",
    "    print(\"⚠ ERROR: No files found!\")\n",
    "    print(f\"  Source files: {len(source_files)}\")\n",
    "    print(f\"  Target files: {len(target_files)}\")\n",
    "    print(\"\\nPossible causes:\")\n",
    "    print(\"  - Data not available on this system (requires HPC/RDS access)\")\n",
    "    print(\"  - Incorrect paths in config/data_paths.yaml\")\n",
    "    print(\"  - Sample number filtering removed all files\")\n",
    "    print(\"\\nTo proceed:\")\n",
    "    print(\"  1. Verify you have access to the RDS data\")\n",
    "    print(\"  2. Check paths in config/data_paths.yaml\")\n",
    "    print(\"  3. Try setting USE_CENTILE_SAMPLES = False in cell above\")\n",
    "else:\n",
    "    print(\n",
    "        f\"✓ Found {len(source_files)} source files and {len(target_files)} target files\"\n",
    "    )\n",
    "    print(\"\\nFitting GMM-OT transformation...\")\n",
    "    print(\"This may take several minutes depending on data size.\")\n",
    "    print(f\"  Max samples per distribution: {transformer.max_samples:,}\")\n",
    "    print(f\"  GMM components: {transformer.n_components}\")\n",
    "    print(f\"  Parallel jobs: {transformer.n_jobs}\")\n",
    "\n",
    "    # Fit using file paths\n",
    "    # The FlowTransformer will load files, concatenate, and fit GMMs\n",
    "    transformer.fit(\n",
    "        source_files=[str(f) for f in source_files],\n",
    "        target_files=[str(f) for f in target_files],\n",
    "    )\n",
    "\n",
    "    print(\"\\n✓ Transformer fitted successfully!\")\n",
    "    print(f\"  Source GMM: {transformer.n_components} components\")\n",
    "    print(f\"  Target GMM: {transformer.n_components} components\")\n",
    "    print(f\"  Transport computed: {transformer.is_fitted_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fitted transformer for later use\n",
    "# This allows you to skip the time-consuming fitting step in future sessions\n",
    "\n",
    "save_path = \"../outputs/flow_transformer_ret.pkl\"\n",
    "transformer.save(save_path)\n",
    "print(f\"✓ Transformer saved to: {save_path}\")\n",
    "print(f\"  You can now load this transformer in future sessions to skip re-fitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a previously saved transformer\n",
    "# Uncomment and run this cell if you want to load a saved transformer instead of fitting\n",
    "\n",
    "# from sysmexcbctools.transfer.sysmexalign import FlowTransformer\n",
    "# save_path = \"../outputs/flow_transformer_ret.pkl\"\n",
    "# transformer = FlowTransformer.load(save_path)\n",
    "# print(f\"✓ Transformer loaded from: {save_path}\")\n",
    "# print(f\"  Channel: {transformer.channel}\")\n",
    "# print(f\"  GMM components: {transformer.n_components}\")\n",
    "# print(f\"  Fitted: {transformer.is_fitted_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transform Source Data\n",
    "\n",
    "Apply the learned transformation to source data files. This will:\n",
    "1. Load each source file\n",
    "2. Apply the GMM-OT transformation to align with target distribution  \n",
    "3. Save transformed files to the output directory\n",
    "\n",
    "Transformed files maintain the same format as input files (`.116.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not transformer.is_fitted_:\n",
    "    print(\"⚠ Transformer not fitted. Skipping transformation.\")\n",
    "    print(\"Run the 'Fit the Transformation' cell above first.\")\n",
    "else:\n",
    "    print(\"Transforming source files to match target distribution...\")\n",
    "    print(f\"  Transforming {len(source_files)} files\")\n",
    "    print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "    # Transform files and save to output directory\n",
    "    output_files = transformer.transform(\n",
    "        source_files=[str(f) for f in source_files],\n",
    "        output_dir=OUTPUT_DIR,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✓ Successfully transformed {len(output_files)} files\")\n",
    "    print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "    if len(output_files) > 0:\n",
    "        print(f\"\\nExample output files:\")\n",
    "        for i, f in enumerate(output_files[:3]):\n",
    "            print(f\"  {i+1}. {Path(f).name}\")\n",
    "        if len(output_files) > 3:\n",
    "            print(f\"  ... and {len(output_files) - 3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validate Transformation Quality\n",
    "\n",
    "Compare the transformed distribution to the target using Wasserstein distance and likelihood scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not transformer.is_fitted_:\n",
    "    print(\"⚠ Transformer not fitted. Skipping visualization.\")\n",
    "elif transformer.source_data_ is None or transformer.target_data_ is None:\n",
    "    print(\"⚠ Fitted data not available. Skipping visualization.\")\n",
    "    print(\n",
    "        \"  To enable visualization, create the transformer with save_fitted_data=True\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Creating distribution comparison plots...\")\n",
    "\n",
    "    # Get the saved downsampled data used for fitting\n",
    "    source_sample_data = transformer.source_data_\n",
    "    target_sample_data = transformer.target_data_\n",
    "\n",
    "    print(f\"  Source data used for fitting: {source_sample_data.shape[0]:,} samples\")\n",
    "    print(f\"  Target data used for fitting: {target_sample_data.shape[0]:,} samples\")\n",
    "\n",
    "    # Transform the source data to compare with target\n",
    "    transformed_sample = transformer.transform_array(source_sample_data)\n",
    "\n",
    "    # Downsample for plotting (use first 20,000 points for clarity)\n",
    "    n_plot = min(20000, len(source_sample_data), len(target_sample_data))\n",
    "    source_plot = source_sample_data[:n_plot]\n",
    "    target_plot = target_sample_data[:n_plot]\n",
    "    transformed_plot = transformed_sample[:n_plot]\n",
    "\n",
    "    print(f\"  Plotting {n_plot:,} cells per distribution\")\n",
    "\n",
    "    # Create figure with multiple subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "    # 1D histograms for each dimension\n",
    "    # Dimension 1 (SFL - Side Fluorescence)\n",
    "    axes[0, 0].hist(\n",
    "        source_plot[:, 0],\n",
    "        bins=50,\n",
    "        alpha=0.5,\n",
    "        label=\"Source (STRIDES)\",\n",
    "        density=True,\n",
    "        color=\"blue\",\n",
    "    )\n",
    "    axes[0, 0].hist(\n",
    "        target_plot[:, 0],\n",
    "        bins=50,\n",
    "        alpha=0.5,\n",
    "        label=\"Target (INTERVAL)\",\n",
    "        density=True,\n",
    "        color=\"orange\",\n",
    "    )\n",
    "    axes[0, 0].hist(\n",
    "        transformed_plot[:, 0],\n",
    "        bins=50,\n",
    "        alpha=0.5,\n",
    "        label=\"Transformed\",\n",
    "        density=True,\n",
    "        color=\"green\",\n",
    "    )\n",
    "    axes[0, 0].set_xlabel(\"SFL (Side Fluorescence)\")\n",
    "    axes[0, 0].set_ylabel(\"Density\")\n",
    "    axes[0, 0].set_title(\"RET Channel - Dimension 1 (SFL)\")\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "    # Dimension 2 (FSC - Forward Scatter)\n",
    "    axes[0, 1].hist(\n",
    "        source_plot[:, 1],\n",
    "        bins=50,\n",
    "        alpha=0.5,\n",
    "        label=\"Source (STRIDES)\",\n",
    "        density=True,\n",
    "        color=\"blue\",\n",
    "    )\n",
    "    axes[0, 1].hist(\n",
    "        target_plot[:, 1],\n",
    "        bins=50,\n",
    "        alpha=0.5,\n",
    "        label=\"Target (INTERVAL)\",\n",
    "        density=True,\n",
    "        color=\"orange\",\n",
    "    )\n",
    "    axes[0, 1].hist(\n",
    "        transformed_plot[:, 1],\n",
    "        bins=50,\n",
    "        alpha=0.5,\n",
    "        label=\"Transformed\",\n",
    "        density=True,\n",
    "        color=\"green\",\n",
    "    )\n",
    "    axes[0, 1].set_xlabel(\"FSC (Forward Scatter)\")\n",
    "    axes[0, 1].set_ylabel(\"Density\")\n",
    "    axes[0, 1].set_title(\"RET Channel - Dimension 2 (FSC)\")\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "    # 2D scatter plots\n",
    "    # Source vs Target\n",
    "    axes[1, 0].scatter(\n",
    "        source_plot[:, 0],\n",
    "        source_plot[:, 1],\n",
    "        s=1,\n",
    "        alpha=0.3,\n",
    "        label=\"Source (STRIDES)\",\n",
    "        color=\"blue\",\n",
    "    )\n",
    "    axes[1, 0].scatter(\n",
    "        target_plot[:, 0],\n",
    "        target_plot[:, 1],\n",
    "        s=1,\n",
    "        alpha=0.3,\n",
    "        label=\"Target (INTERVAL)\",\n",
    "        color=\"orange\",\n",
    "    )\n",
    "    axes[1, 0].set_xlabel(\"SFL (Side Fluorescence)\")\n",
    "    axes[1, 0].set_ylabel(\"FSC (Forward Scatter)\")\n",
    "    axes[1, 0].set_title(\"Before Transformation: Source vs Target\")\n",
    "    axes[1, 0].legend(markerscale=10)\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "    # Transformed vs Target\n",
    "    axes[1, 1].scatter(\n",
    "        transformed_plot[:, 0],\n",
    "        transformed_plot[:, 1],\n",
    "        s=1,\n",
    "        alpha=0.3,\n",
    "        label=\"Transformed\",\n",
    "        color=\"green\",\n",
    "    )\n",
    "    axes[1, 1].scatter(\n",
    "        target_plot[:, 0],\n",
    "        target_plot[:, 1],\n",
    "        s=1,\n",
    "        alpha=0.3,\n",
    "        label=\"Target (INTERVAL)\",\n",
    "        color=\"orange\",\n",
    "    )\n",
    "    axes[1, 1].set_xlabel(\"SFL (Side Fluorescence)\")\n",
    "    axes[1, 1].set_ylabel(\"FSC (Forward Scatter)\")\n",
    "    axes[1, 1].set_title(\"After Transformation: Transformed vs Target\")\n",
    "    axes[1, 1].legend(markerscale=10)\n",
    "    axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../outputs/distribution_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n✓ Distribution plots saved to ../outputs/distribution_comparison.png\")\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"  - Top row: 1D marginal distributions for each dimension\")\n",
    "    print(\"  - Bottom left: Original source (blue) vs target (orange)\")\n",
    "    print(\"  - Bottom right: Transformed (green) should match target (orange)\")\n",
    "    print(\"  - Success = green and orange distributions overlap well\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not transformer.is_fitted_:\n",
    "    print(\"⚠ Transformer not fitted. Skipping enhanced visualization.\")\n",
    "elif transformer.source_data_ is None or transformer.target_data_ is None:\n",
    "    print(\"⚠ Fitted data not available. Skipping enhanced visualization.\")\n",
    "else:\n",
    "    import json\n",
    "    from matplotlib.path import Path as MplPath\n",
    "    from matplotlib.patches import Polygon\n",
    "\n",
    "    print(\"Creating enhanced transformation visualizations...\")\n",
    "\n",
    "    # Get data\n",
    "    source_data = transformer.source_data_\n",
    "    target_data = transformer.target_data_\n",
    "    transformed_data = transformer.transform_array(source_data)\n",
    "\n",
    "    # Load gates for per-population analysis\n",
    "    gate_file = \"../../sysmexcbctools/transfer/flow_gates/json_gates/RET_gates.json\"\n",
    "    with open(gate_file, \"r\") as f:\n",
    "        gates = json.load(f)\n",
    "\n",
    "    # Downsample for visualization\n",
    "    n_plot = min(30000, len(source_data), len(target_data))\n",
    "    np.random.seed(42)\n",
    "    plot_idx = np.random.choice(len(source_data), n_plot, replace=False)\n",
    "\n",
    "    source_plot = source_data[plot_idx]\n",
    "    target_plot = target_data[np.random.choice(len(target_data), n_plot, replace=False)]\n",
    "    transformed_plot = transformed_data[plot_idx]\n",
    "\n",
    "    print(f\"  Visualizing {n_plot:,} cells per distribution\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # Figure 1: 3-Panel Comparison with 2D Density\n",
    "    # ========================================================================\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "    # Common settings\n",
    "    xlim = (0, 260)\n",
    "    ylim = (0, 260)\n",
    "    bins = 100\n",
    "\n",
    "    # Helper function to add gates\n",
    "    def add_gates_to_plot(ax, gates_dict, alpha=0.6):\n",
    "        colors = {\"RBC\": \"red\", \"RET\": \"blue\", \"PLT\": \"green\"}\n",
    "        for pop_name, coords in gates_dict.items():\n",
    "            if len(coords) > 0:\n",
    "                poly = Polygon(\n",
    "                    coords,\n",
    "                    fill=False,\n",
    "                    edgecolor=colors.get(pop_name, \"white\"),\n",
    "                    linewidth=2,\n",
    "                    alpha=alpha,\n",
    "                    linestyle=\"--\",\n",
    "                )\n",
    "                ax.add_patch(poly)\n",
    "\n",
    "    # Row 1: Scatter plots\n",
    "    # Panel 1: Source\n",
    "    ax = axes[0, 0]\n",
    "    ax.scatter(\n",
    "        source_plot[:, 0],\n",
    "        source_plot[:, 1],\n",
    "        s=0.5,\n",
    "        alpha=0.2,\n",
    "        c=\"blue\",\n",
    "        rasterized=True,\n",
    "    )\n",
    "    add_gates_to_plot(ax, gates)\n",
    "    ax.set_xlabel(\"SFL (Side Fluorescence)\", fontsize=11)\n",
    "    ax.set_ylabel(\"FSC (Forward Scatter)\", fontsize=11)\n",
    "    ax.set_title(\"Source (STRIDES)\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    # Panel 2: Transformed\n",
    "    ax = axes[0, 1]\n",
    "    ax.scatter(\n",
    "        transformed_plot[:, 0],\n",
    "        transformed_plot[:, 1],\n",
    "        s=0.5,\n",
    "        alpha=0.2,\n",
    "        c=\"green\",\n",
    "        rasterized=True,\n",
    "    )\n",
    "    add_gates_to_plot(ax, gates)\n",
    "    ax.set_xlabel(\"SFL (Side Fluorescence)\", fontsize=11)\n",
    "    ax.set_ylabel(\"FSC (Forward Scatter)\", fontsize=11)\n",
    "    ax.set_title(\"Transformed\", fontsize=13, fontweight=\"bold\", color=\"green\")\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    # Panel 3: Target\n",
    "    ax = axes[0, 2]\n",
    "    ax.scatter(\n",
    "        target_plot[:, 0],\n",
    "        target_plot[:, 1],\n",
    "        s=0.5,\n",
    "        alpha=0.2,\n",
    "        c=\"orange\",\n",
    "        rasterized=True,\n",
    "    )\n",
    "    add_gates_to_plot(ax, gates)\n",
    "    ax.set_xlabel(\"SFL (Side Fluorescence)\", fontsize=11)\n",
    "    ax.set_ylabel(\"FSC (Forward Scatter)\", fontsize=11)\n",
    "    ax.set_title(\"Target (INTERVAL)\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    # Row 2: 2D Density Heatmaps\n",
    "    # Panel 1: Source density\n",
    "    ax = axes[1, 0]\n",
    "    h_source = ax.hist2d(\n",
    "        source_plot[:, 0],\n",
    "        source_plot[:, 1],\n",
    "        bins=bins,\n",
    "        cmap=\"Blues\",\n",
    "        range=[xlim, ylim],\n",
    "        density=True,\n",
    "        cmin=1e-6,\n",
    "    )\n",
    "    add_gates_to_plot(ax, gates)\n",
    "    ax.set_xlabel(\"SFL (Side Fluorescence)\", fontsize=11)\n",
    "    ax.set_ylabel(\"FSC (Forward Scatter)\", fontsize=11)\n",
    "    ax.set_title(\"Source Density\", fontsize=12)\n",
    "    plt.colorbar(h_source[3], ax=ax, label=\"Density\")\n",
    "\n",
    "    # Panel 2: Transformed density\n",
    "    ax = axes[1, 1]\n",
    "    h_trans = ax.hist2d(\n",
    "        transformed_plot[:, 0],\n",
    "        transformed_plot[:, 1],\n",
    "        bins=bins,\n",
    "        cmap=\"Greens\",\n",
    "        range=[xlim, ylim],\n",
    "        density=True,\n",
    "        cmin=1e-6,\n",
    "    )\n",
    "    add_gates_to_plot(ax, gates)\n",
    "    ax.set_xlabel(\"SFL (Side Fluorescence)\", fontsize=11)\n",
    "    ax.set_ylabel(\"FSC (Forward Scatter)\", fontsize=11)\n",
    "    ax.set_title(\"Transformed Density\", fontsize=12)\n",
    "    plt.colorbar(h_trans[3], ax=ax, label=\"Density\")\n",
    "\n",
    "    # Panel 3: Target density\n",
    "    ax = axes[1, 2]\n",
    "    h_target = ax.hist2d(\n",
    "        target_plot[:, 0],\n",
    "        target_plot[:, 1],\n",
    "        bins=bins,\n",
    "        cmap=\"Oranges\",\n",
    "        range=[xlim, ylim],\n",
    "        density=True,\n",
    "        cmin=1e-6,\n",
    "    )\n",
    "    add_gates_to_plot(ax, gates)\n",
    "    ax.set_xlabel(\"SFL (Side Fluorescence)\", fontsize=11)\n",
    "    ax.set_ylabel(\"FSC (Forward Scatter)\", fontsize=11)\n",
    "    ax.set_title(\"Target Density\", fontsize=12)\n",
    "    plt.colorbar(h_target[3], ax=ax, label=\"Density\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        \"../outputs/transformation_3panel_comparison.png\", dpi=150, bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    print(\n",
    "        \"✓ 3-panel comparison saved to ../outputs/transformation_3panel_comparison.png\\n\"\n",
    "    )\n",
    "\n",
    "    # ========================================================================\n",
    "    # Figure 2: Per-Population Comparison\n",
    "    # ========================================================================\n",
    "\n",
    "    def classify_by_gate(data, gates_dict):\n",
    "        \"\"\"Classify points by gate membership\"\"\"\n",
    "        labels = np.full(len(data), -1, dtype=int)  # -1 = ungated\n",
    "        label_names = {}\n",
    "\n",
    "        for label_idx, (pop_name, coords) in enumerate(gates_dict.items()):\n",
    "            if len(coords) == 0:\n",
    "                continue\n",
    "            path = MplPath(coords)\n",
    "            mask = path.contains_points(data)\n",
    "            labels[mask] = label_idx\n",
    "            label_names[label_idx] = pop_name\n",
    "\n",
    "        return labels, label_names\n",
    "\n",
    "    # Classify points\n",
    "    source_labels, label_names = classify_by_gate(source_plot, gates)\n",
    "    target_labels, _ = classify_by_gate(target_plot, gates)\n",
    "    transformed_labels, _ = classify_by_gate(transformed_plot, gates)\n",
    "\n",
    "    # Create per-population figure\n",
    "    n_pops = len(label_names)\n",
    "    fig, axes = plt.subplots(n_pops, 3, figsize=(16, 4 * n_pops))\n",
    "\n",
    "    if n_pops == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "\n",
    "    pop_colors = {\"RBC\": \"red\", \"RET\": \"blue\", \"PLT\": \"green\"}\n",
    "\n",
    "    for row_idx, (label_idx, pop_name) in enumerate(label_names.items()):\n",
    "        # Get points in this population\n",
    "        source_pop = source_plot[source_labels == label_idx]\n",
    "        target_pop = target_plot[target_labels == label_idx]\n",
    "        transformed_pop = transformed_plot[transformed_labels == label_idx]\n",
    "\n",
    "        color = pop_colors.get(pop_name, \"gray\")\n",
    "\n",
    "        # Column 1: Source vs Target overlay for this population\n",
    "        ax = axes[row_idx, 0]\n",
    "        if len(source_pop) > 0:\n",
    "            ax.scatter(\n",
    "                source_pop[:, 0],\n",
    "                source_pop[:, 1],\n",
    "                s=1,\n",
    "                alpha=0.3,\n",
    "                c=\"blue\",\n",
    "                label=f\"Source {pop_name} (n={len(source_pop):,})\",\n",
    "                rasterized=True,\n",
    "            )\n",
    "        if len(target_pop) > 0:\n",
    "            ax.scatter(\n",
    "                target_pop[:, 0],\n",
    "                target_pop[:, 1],\n",
    "                s=1,\n",
    "                alpha=0.3,\n",
    "                c=\"orange\",\n",
    "                label=f\"Target {pop_name} (n={len(target_pop):,})\",\n",
    "                rasterized=True,\n",
    "            )\n",
    "        ax.set_xlabel(\"SFL\", fontsize=10)\n",
    "        ax.set_ylabel(\"FSC\", fontsize=10)\n",
    "        ax.set_title(f\"{pop_name}: Source vs Target\", fontsize=11, fontweight=\"bold\")\n",
    "        ax.legend(markerscale=5, fontsize=8)\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "        # Column 2: Transformed vs Target overlay for this population\n",
    "        ax = axes[row_idx, 1]\n",
    "        if len(transformed_pop) > 0:\n",
    "            ax.scatter(\n",
    "                transformed_pop[:, 0],\n",
    "                transformed_pop[:, 1],\n",
    "                s=1,\n",
    "                alpha=0.3,\n",
    "                c=\"green\",\n",
    "                label=f\"Transformed {pop_name} (n={len(transformed_pop):,})\",\n",
    "                rasterized=True,\n",
    "            )\n",
    "        if len(target_pop) > 0:\n",
    "            ax.scatter(\n",
    "                target_pop[:, 0],\n",
    "                target_pop[:, 1],\n",
    "                s=1,\n",
    "                alpha=0.3,\n",
    "                c=\"orange\",\n",
    "                label=f\"Target {pop_name} (n={len(target_pop):,})\",\n",
    "                rasterized=True,\n",
    "            )\n",
    "        ax.set_xlabel(\"SFL\", fontsize=10)\n",
    "        ax.set_ylabel(\"FSC\", fontsize=10)\n",
    "        ax.set_title(\n",
    "            f\"{pop_name}: Transformed vs Target\",\n",
    "            fontsize=11,\n",
    "            fontweight=\"bold\",\n",
    "            color=\"green\",\n",
    "        )\n",
    "        ax.legend(markerscale=5, fontsize=8)\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "        # Column 3: 1D marginal comparisons\n",
    "        ax = axes[row_idx, 2]\n",
    "\n",
    "        # SFL marginal (horizontal)\n",
    "        ax_sfl = ax\n",
    "        if len(source_pop) > 0:\n",
    "            ax_sfl.hist(\n",
    "                source_pop[:, 0],\n",
    "                bins=50,\n",
    "                alpha=0.4,\n",
    "                color=\"blue\",\n",
    "                density=True,\n",
    "                label=\"Source\",\n",
    "            )\n",
    "        if len(transformed_pop) > 0:\n",
    "            ax_sfl.hist(\n",
    "                transformed_pop[:, 0],\n",
    "                bins=50,\n",
    "                alpha=0.4,\n",
    "                color=\"green\",\n",
    "                density=True,\n",
    "                label=\"Transformed\",\n",
    "            )\n",
    "        if len(target_pop) > 0:\n",
    "            ax_sfl.hist(\n",
    "                target_pop[:, 0],\n",
    "                bins=50,\n",
    "                alpha=0.4,\n",
    "                color=\"orange\",\n",
    "                density=True,\n",
    "                label=\"Target\",\n",
    "            )\n",
    "        ax_sfl.set_xlabel(\"SFL (Side Fluorescence)\", fontsize=10)\n",
    "        ax_sfl.set_ylabel(\"Density\", fontsize=10)\n",
    "        ax_sfl.set_title(f\"{pop_name}: SFL Marginal Distribution\", fontsize=11)\n",
    "        ax_sfl.legend(fontsize=8)\n",
    "        ax_sfl.grid(alpha=0.3)\n",
    "        ax_sfl.set_xlim(xlim)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        \"../outputs/transformation_per_population.png\", dpi=150, bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    print(\n",
    "        \"✓ Per-population comparison saved to ../outputs/transformation_per_population.png\\n\"\n",
    "    )\n",
    "\n",
    "    # ========================================================================\n",
    "    # Figure 3: Overlay Comparison (Transformed vs Target)\n",
    "    # ========================================================================\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Panel 1: Direct overlay\n",
    "    ax = axes[0]\n",
    "    ax.scatter(\n",
    "        target_plot[:, 0],\n",
    "        target_plot[:, 1],\n",
    "        s=1,\n",
    "        alpha=0.15,\n",
    "        c=\"orange\",\n",
    "        label=f\"Target (n={len(target_plot):,})\",\n",
    "        rasterized=True,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        transformed_plot[:, 0],\n",
    "        transformed_plot[:, 1],\n",
    "        s=1,\n",
    "        alpha=0.15,\n",
    "        c=\"green\",\n",
    "        label=f\"Transformed (n={len(transformed_plot):,})\",\n",
    "        rasterized=True,\n",
    "    )\n",
    "    add_gates_to_plot(ax, gates)\n",
    "    ax.set_xlabel(\"SFL (Side Fluorescence)\", fontsize=11)\n",
    "    ax.set_ylabel(\"FSC (Forward Scatter)\", fontsize=11)\n",
    "    ax.set_title(\n",
    "        \"Overlay: Transformed (green) vs Target (orange)\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax.legend(markerscale=10, fontsize=10)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "    # Panel 2: Density difference (Transformed - Target)\n",
    "    ax = axes[1]\n",
    "\n",
    "    # Compute 2D histograms\n",
    "    H_trans, xedges, yedges = np.histogram2d(\n",
    "        transformed_plot[:, 0],\n",
    "        transformed_plot[:, 1],\n",
    "        bins=bins,\n",
    "        range=[xlim, ylim],\n",
    "        density=True,\n",
    "    )\n",
    "    H_target, _, _ = np.histogram2d(\n",
    "        target_plot[:, 0],\n",
    "        target_plot[:, 1],\n",
    "        bins=bins,\n",
    "        range=[xlim, ylim],\n",
    "        density=True,\n",
    "    )\n",
    "\n",
    "    # Compute difference\n",
    "    H_diff = H_trans - H_target\n",
    "\n",
    "    # Plot difference\n",
    "    im = ax.imshow(\n",
    "        H_diff.T,\n",
    "        origin=\"lower\",\n",
    "        extent=[xlim[0], xlim[1], ylim[0], ylim[1]],\n",
    "        cmap=\"RdBu_r\",\n",
    "        vmin=-np.percentile(np.abs(H_diff), 95),\n",
    "        vmax=np.percentile(np.abs(H_diff), 95),\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "    add_gates_to_plot(ax, gates, alpha=0.8)\n",
    "    ax.set_xlabel(\"SFL (Side Fluorescence)\", fontsize=11)\n",
    "    ax.set_ylabel(\"FSC (Forward Scatter)\", fontsize=11)\n",
    "    ax.set_title(\n",
    "        \"Density Difference: Transformed - Target\", fontsize=12, fontweight=\"bold\"\n",
    "    )\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label(\"Density Difference\", fontsize=10)\n",
    "    ax.grid(alpha=0.3, color=\"white\", linewidth=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        \"../outputs/transformation_overlay_comparison.png\", dpi=150, bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    print(\n",
    "        \"✓ Overlay comparison saved to ../outputs/transformation_overlay_comparison.png\\n\"\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"VISUALIZATION SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nGenerated three comprehensive visualization figures:\")\n",
    "    print(\"  1. 3-panel comparison: Source | Transformed | Target\")\n",
    "    print(\"     - Top row: Scatter plots with gate overlays\")\n",
    "    print(\"     - Bottom row: 2D density heatmaps\")\n",
    "    print()\n",
    "    print(\"  2. Per-population comparison: Separate analysis for each gated population\")\n",
    "    print(\"     - Shows how well transformation works for RBC, RET, PLT separately\")\n",
    "    print(\"     - Critical for validating rare population handling\")\n",
    "    print()\n",
    "    print(\"  3. Overlay comparison: Direct visual comparison\")\n",
    "    print(\"     - Left: Transformed (green) vs Target (orange) overlay\")\n",
    "    print(\"     - Right: Density difference map (red=excess, blue=deficit)\")\n",
    "    print()\n",
    "    print(\"Interpretation:\")\n",
    "    print(\"  - Transformed should visually match Target distribution\")\n",
    "    print(\"  - Density difference map should be mostly white (neutral)\")\n",
    "    print(\"  - Per-population plots show if rare populations are well-aligned\")\n",
    "    print(\"  - Red/blue regions in difference map indicate misalignment\")\n",
    "\n",
    "    print(\"\\n✓ Enhanced visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Enhanced Transformation Visualization\n",
    "\n",
    "Comprehensive visual comparison of the transformation quality:\n",
    "- **3-panel comparison**: Source | Transformed | Target side-by-side\n",
    "- **2D density heatmaps**: Show distribution densities for detailed comparison\n",
    "- **Per-population overlays**: Evaluate transformation quality for each gated cell population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not transformer.is_fitted_:\n",
    "    print(\"⚠ Transformer not fitted. Skipping metrics computation.\")\n",
    "elif transformer.source_data_ is None or transformer.target_data_ is None:\n",
    "    print(\"⚠ Fitted data not available. Skipping metrics computation.\")\n",
    "else:\n",
    "    from scipy.stats import wasserstein_distance\n",
    "    from scipy.spatial.distance import cdist\n",
    "    import ot\n",
    "\n",
    "    print(\"Computing distribution distance metrics...\")\n",
    "\n",
    "    # Get data\n",
    "    source_data = transformer.source_data_\n",
    "    target_data = transformer.target_data_\n",
    "    transformed_data = transformer.transform_array(source_data)\n",
    "\n",
    "    # Downsample for faster computation if needed\n",
    "    n_metric = min(50000, len(source_data), len(target_data))\n",
    "    np.random.seed(42)\n",
    "    source_metric = source_data[\n",
    "        np.random.choice(len(source_data), n_metric, replace=False)\n",
    "    ]\n",
    "    target_metric = target_data[\n",
    "        np.random.choice(len(target_data), n_metric, replace=False)\n",
    "    ]\n",
    "    transformed_metric = transformer.transform_array(source_metric)\n",
    "\n",
    "    source_metric = source_metric.astype(np.float64)\n",
    "    target_metric = target_metric.astype(np.float64)\n",
    "    transformed_metric = transformed_metric.astype(np.float64)\n",
    "\n",
    "    print(f\"  Using {n_metric:,} samples for metric computation\\n\")\n",
    "\n",
    "    # ===== 1D Wasserstein Distances (per dimension) =====\n",
    "    print(\"=\" * 60)\n",
    "    print(\"1D Wasserstein Distance (per dimension)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    dim_names = [\"SFL (Side Fluorescence)\", \"FSC (Forward Scatter)\"]\n",
    "    for dim in range(2):\n",
    "        w_source_target = ot.emd2_1d(source_metric[:, dim], target_metric[:, dim])\n",
    "        w_trans_target = ot.emd2_1d(transformed_metric[:, dim], target_metric[:, dim])\n",
    "        improvement = (\n",
    "            (1 - w_trans_target / w_source_target) * 100 if w_source_target > 0 else 0\n",
    "        )\n",
    "\n",
    "        print(f\"\\n{dim_names[dim]}:\")\n",
    "        print(f\"  Source → Target:      {w_source_target:.4f}\")\n",
    "        print(f\"  Transformed → Target: {w_trans_target:.4f}\")\n",
    "        print(f\"  Improvement:          {improvement:+.1f}%\")\n",
    "\n",
    "    # ===== 2D Wasserstein Distance (approximation using sliced Wasserstein) =====\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"2D Wasserstein Distance (approximate)\")\n",
    "    print(\"=\" * 60)\n",
    "    # print(\"(Average of 1D Wasserstein over 50 random projections)\")\n",
    "\n",
    "    # def sliced_wasserstein(X, Y, n_projections=50, seed=42):\n",
    "    #     \"\"\"Compute sliced Wasserstein distance (approximation of 2D Wasserstein)\"\"\"\n",
    "    #     np.random.seed(seed)\n",
    "    #     distances = []\n",
    "    #     for _ in range(n_projections):\n",
    "    #         # Random direction\n",
    "    #         theta = np.random.uniform(0, 2 * np.pi)\n",
    "    #         direction = np.array([np.cos(theta), np.sin(theta)])\n",
    "    #         # Project data\n",
    "    #         X_proj = X @ direction\n",
    "    #         Y_proj = Y @ direction\n",
    "    #         # 1D Wasserstein\n",
    "    #         distances.append(wasserstein_distance(X_proj, Y_proj))\n",
    "    #     return np.mean(distances)\n",
    "\n",
    "    def sliced_wasserstein(X, Y, n_projections=500, seed=42):\n",
    "        \"\"\"Compute sliced Wasserstein distance using POT library\"\"\"\n",
    "        return ot.sliced_wasserstein_distance(\n",
    "            X, Y, n_projections=n_projections, seed=seed\n",
    "        )\n",
    "\n",
    "    # sw_source_target = sliced_wasserstein(source_metric, target_metric)\n",
    "    # sw_trans_target = sliced_wasserstein(transformed_metric, target_metric)\n",
    "    # sw_improvement = (1 - sw_trans_target / sw_source_target) * 100 if sw_source_target > 0 else 0\n",
    "\n",
    "    # again using a subset but computing actual 2D Wasserstein distance via POT\n",
    "    n_samples_wasserstein = 5000\n",
    "\n",
    "    sw_source_target = ot.solve_sample(\n",
    "        source_metric[\n",
    "            np.random.choice(len(source_metric), n_samples_wasserstein, replace=False)\n",
    "        ],\n",
    "        target_metric[\n",
    "            np.random.choice(len(target_metric), n_samples_wasserstein, replace=False)\n",
    "        ],\n",
    "        metric=\"euclidean\",\n",
    "        verbose=True,\n",
    "    ).value\n",
    "    sw_trans_target = ot.solve_sample(\n",
    "        transformed_metric[\n",
    "            np.random.choice(\n",
    "                len(transformed_metric), n_samples_wasserstein, replace=False\n",
    "            )\n",
    "        ],\n",
    "        target_metric[\n",
    "            np.random.choice(len(target_metric), n_samples_wasserstein, replace=False)\n",
    "        ],\n",
    "        metric=\"euclidean\",\n",
    "        verbose=True,\n",
    "    ).value\n",
    "    sw_improvement = (\n",
    "        (1 - sw_trans_target / sw_source_target) * 100 if sw_source_target > 0 else 0\n",
    "    )\n",
    "\n",
    "    print(f\"\\n  Source → Target:      {sw_source_target:.4f}\")\n",
    "    print(f\"  Transformed → Target: {sw_trans_target:.4f}\")\n",
    "    print(f\"  Improvement:          {sw_improvement:+.1f}%\")\n",
    "\n",
    "    # ===== Maximum Mean Discrepancy (MMD) =====\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Maximum Mean Discrepancy (MMD)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"(Kernel-based distance, using Gaussian kernel with bandwidth=10)\")\n",
    "\n",
    "    def compute_mmd(X, Y, bandwidth=10.0):\n",
    "        \"\"\"Compute Maximum Mean Discrepancy with Gaussian kernel\"\"\"\n",
    "        # Use subset for computational efficiency\n",
    "        n = min(5000, len(X), len(Y))\n",
    "        X_sub = X[np.random.choice(len(X), n, replace=False)]\n",
    "        Y_sub = Y[np.random.choice(len(Y), n, replace=False)]\n",
    "\n",
    "        # Gaussian kernel\n",
    "        def kernel(x, y, bandwidth):\n",
    "            return np.exp(-np.sum((x - y) ** 2) / (2 * bandwidth**2))\n",
    "\n",
    "        # Compute kernel matrices\n",
    "        XX = cdist(X_sub, X_sub, metric=\"sqeuclidean\")\n",
    "        YY = cdist(Y_sub, Y_sub, metric=\"sqeuclidean\")\n",
    "        XY = cdist(X_sub, Y_sub, metric=\"sqeuclidean\")\n",
    "\n",
    "        # Apply Gaussian kernel\n",
    "        K_XX = np.exp(-XX / (2 * bandwidth**2))\n",
    "        K_YY = np.exp(-YY / (2 * bandwidth**2))\n",
    "        K_XY = np.exp(-XY / (2 * bandwidth**2))\n",
    "\n",
    "        # MMD^2 estimate\n",
    "        mmd_sq = K_XX.mean() + K_YY.mean() - 2 * K_XY.mean()\n",
    "        return np.sqrt(max(0, mmd_sq))  # Ensure non-negative\n",
    "\n",
    "    mmd_source_target = compute_mmd(source_metric, target_metric)\n",
    "    mmd_trans_target = compute_mmd(transformed_metric, target_metric)\n",
    "    mmd_improvement = (\n",
    "        (1 - mmd_trans_target / mmd_source_target) * 100 if mmd_source_target > 0 else 0\n",
    "    )\n",
    "\n",
    "    print(f\"\\n  Source → Target:      {mmd_source_target:.6f}\")\n",
    "    print(f\"  Transformed → Target: {mmd_trans_target:.6f}\")\n",
    "    print(f\"  Improvement:          {mmd_improvement:+.1f}%\")\n",
    "\n",
    "    # ===== Per-Population Analysis Using Gates =====\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Per-Population Distance Metrics (Gate-Based)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Load gates\n",
    "    import json\n",
    "    from matplotlib.path import Path as MplPath\n",
    "\n",
    "    gate_file = \"../../sysmexcbctools/transfer/flow_gates/json_gates/RET_gates.json\"\n",
    "    with open(gate_file, \"r\") as f:\n",
    "        gates = json.load(f)\n",
    "\n",
    "    def classify_by_gate(data, gates_dict):\n",
    "        \"\"\"Classify points by gate membership\"\"\"\n",
    "        labels = np.full(len(data), -1, dtype=int)  # -1 = ungated\n",
    "        label_names = {}\n",
    "\n",
    "        for label_idx, (pop_name, coords) in enumerate(gates_dict.items()):\n",
    "            if len(coords) == 0:\n",
    "                continue\n",
    "            path = MplPath(coords)\n",
    "            mask = path.contains_points(data)\n",
    "            labels[mask] = label_idx\n",
    "            label_names[label_idx] = pop_name\n",
    "\n",
    "        return labels, label_names\n",
    "\n",
    "    # Classify all points\n",
    "    source_labels, label_names = classify_by_gate(source_metric, gates)\n",
    "    target_labels, _ = classify_by_gate(target_metric, gates)\n",
    "    transformed_labels, _ = classify_by_gate(transformed_metric, gates)\n",
    "\n",
    "    print(\"\\nPer-population 2D Sliced Wasserstein Distance:\")\n",
    "    print()\n",
    "\n",
    "    for label_idx, pop_name in label_names.items():\n",
    "        # Get points in this population\n",
    "        source_pop = source_metric[source_labels == label_idx]\n",
    "        target_pop = target_metric[target_labels == label_idx]\n",
    "        transformed_pop = transformed_metric[transformed_labels == label_idx]\n",
    "\n",
    "        if len(source_pop) < 100 or len(target_pop) < 100:\n",
    "            print(\n",
    "                f\"  {pop_name}: Insufficient data (source={len(source_pop)}, target={len(target_pop)})\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Compute sliced Wasserstein for this population\n",
    "        sw_pop_source = sliced_wasserstein(source_pop, target_pop, n_projections=30)\n",
    "        sw_pop_trans = sliced_wasserstein(transformed_pop, target_pop, n_projections=30)\n",
    "        sw_pop_improvement = (\n",
    "            (1 - sw_pop_trans / sw_pop_source) * 100 if sw_pop_source > 0 else 0\n",
    "        )\n",
    "\n",
    "        print(f\"  {pop_name}:\")\n",
    "        print(\n",
    "            f\"    Source → Target:      {sw_pop_source:.4f} (n_source={len(source_pop):,}, n_target={len(target_pop):,})\"\n",
    "        )\n",
    "        print(\n",
    "            f\"    Transformed → Target: {sw_pop_trans:.4f} (n_transformed={len(transformed_pop):,})\"\n",
    "        )\n",
    "        print(f\"    Improvement:          {sw_pop_improvement:+.1f}%\")\n",
    "        print()\n",
    "\n",
    "    # ===== Summary =====\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nOverall transformation effectiveness:\")\n",
    "    print(f\"  2D Sliced Wasserstein: {sw_improvement:+.1f}% improvement\")\n",
    "    print(f\"  MMD:                   {mmd_improvement:+.1f}% improvement\")\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"  - Positive % = transformation reduced distance (good)\")\n",
    "    print(\"  - Negative % = transformation increased distance (bad)\")\n",
    "    print(\"  - Goal: All metrics show positive improvement\")\n",
    "    print(\"  - Per-population metrics show if rare populations are handled well\")\n",
    "\n",
    "    # Save metrics to dict for later use\n",
    "    metrics_summary = {\n",
    "        \"sliced_wasserstein\": {\n",
    "            \"source_target\": sw_source_target,\n",
    "            \"transformed_target\": sw_trans_target,\n",
    "            \"improvement_pct\": sw_improvement,\n",
    "        },\n",
    "        \"mmd\": {\n",
    "            \"source_target\": mmd_source_target,\n",
    "            \"transformed_target\": mmd_trans_target,\n",
    "            \"improvement_pct\": mmd_improvement,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    print(\"\\n✓ Metrics computation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Quantitative Distribution Distance Metrics\n",
    "\n",
    "To rigorously assess transformation quality, we'll compute several distribution distance metrics comparing:\n",
    "- **Source vs Target**: Original distance (what we're trying to fix)\n",
    "- **Transformed vs Target**: After transformation (should be much smaller)\n",
    "\n",
    "Metrics include:\n",
    "- **Wasserstein distance**: Optimal transport cost (lower is better)\n",
    "- **Maximum Mean Discrepancy (MMD)**: Kernel-based distance\n",
    "- **Per-population analysis**: Evaluate each cell population separately using gates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac1f1f",
   "metadata": {},
   "source": [
    "## Diagnostic: GMM Fit Quality Analysis\n",
    "\n",
    "Let's diagnose potential GMM collapse by visualizing how well the GMM components fit the actual data distribution. We'll overlay the manually-defined flow cytometry gates to see if important populations are being captured.\n",
    "\n",
    "⚠️ **Note on Gates**: The gate definitions used here are manually derived through visual inspection of flow cytometry data and should be considered approximate. Official Sysmex-provided gates or expert-validated gates would be preferable for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Polygon\n",
    "import numpy as np\n",
    "\n",
    "# Load the manually-defined gates for RET channel\n",
    "gate_file = \"../../sysmexcbctools/transfer/flow_gates/json_gates/RET_gates.json\"\n",
    "with open(gate_file, \"r\") as f:\n",
    "    gates = json.load(f)\n",
    "\n",
    "print(\"Available gate populations:\")\n",
    "for pop_name, coords in gates.items():\n",
    "    print(f\"  - {pop_name}: {len(coords)} vertices\")\n",
    "\n",
    "# Get data and GMM fits\n",
    "source_data = transformer.source_data_\n",
    "target_data = transformer.target_data_\n",
    "source_gmm = transformer.source_gmm_\n",
    "target_gmm = transformer.target_gmm_\n",
    "\n",
    "# Downsample for visualization\n",
    "n_plot = min(50000, len(source_data), len(target_data))\n",
    "np.random.seed(42)\n",
    "source_plot_idx = np.random.choice(len(source_data), n_plot, replace=False)\n",
    "target_plot_idx = np.random.choice(len(target_data), n_plot, replace=False)\n",
    "\n",
    "source_plot = source_data[source_plot_idx]\n",
    "target_plot = target_data[target_plot_idx]\n",
    "\n",
    "# Create comprehensive diagnostic figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "\n",
    "# Helper function to add gates to plot\n",
    "def add_gates_to_plot(ax, gates_dict, alpha=0.5):\n",
    "    colors = {\"RBC\": \"red\", \"RET\": \"blue\", \"PLT\": \"green\"}\n",
    "    for pop_name, coords in gates_dict.items():\n",
    "        if len(coords) > 0:\n",
    "            poly = Polygon(\n",
    "                coords,\n",
    "                fill=False,\n",
    "                edgecolor=colors.get(pop_name, \"gray\"),\n",
    "                linewidth=2,\n",
    "                alpha=alpha,\n",
    "                label=f\"{pop_name} gate\",\n",
    "            )\n",
    "            ax.add_patch(poly)\n",
    "\n",
    "\n",
    "# Helper function to add GMM components\n",
    "def add_gmm_components(\n",
    "    ax, gmm, color=\"red\", marker=\"x\", size=200, alpha=0.8, label=\"GMM\"\n",
    "):\n",
    "    means = gmm.means_\n",
    "    # Get component weights for sizing\n",
    "    weights = gmm.weights_\n",
    "    sizes = weights * size * 10  # Scale by weights\n",
    "    ax.scatter(\n",
    "        means[:, 0],\n",
    "        means[:, 1],\n",
    "        c=color,\n",
    "        marker=marker,\n",
    "        s=sizes,\n",
    "        alpha=alpha,\n",
    "        edgecolors=\"black\",\n",
    "        linewidths=1.5,\n",
    "        label=label,\n",
    "        zorder=10,\n",
    "    )\n",
    "\n",
    "    # Add component numbers\n",
    "    for i, (mean, weight) in enumerate(zip(means, weights)):\n",
    "        ax.annotate(\n",
    "            f\"{i}\\n({weight:.2%})\",\n",
    "            mean,\n",
    "            fontsize=6,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            bbox=dict(\n",
    "                boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.7, edgecolor=color\n",
    "            ),\n",
    "        )\n",
    "\n",
    "\n",
    "# ===== Plot 1: Source data with Source GMM =====\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(\n",
    "    source_plot[:, 0], source_plot[:, 1], s=1, alpha=0.1, c=\"blue\", rasterized=True\n",
    ")\n",
    "add_gates_to_plot(ax, gates)\n",
    "add_gmm_components(ax, source_gmm, color=\"red\", label=\"Source GMM components\")\n",
    "ax.set_xlabel(\"SFL (Side Fluorescence)\")\n",
    "ax.set_ylabel(\"FSC (Forward Scatter)\")\n",
    "ax.set_title(\"Source Data + Source GMM Components + Manual Gates\")\n",
    "ax.set_xlim(0, 260)\n",
    "ax.set_ylim(0, 260)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend(loc=\"upper right\", fontsize=8)\n",
    "\n",
    "# ===== Plot 2: Target data with Target GMM =====\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(\n",
    "    target_plot[:, 0], target_plot[:, 1], s=1, alpha=0.1, c=\"orange\", rasterized=True\n",
    ")\n",
    "add_gates_to_plot(ax, gates)\n",
    "add_gmm_components(ax, target_gmm, color=\"darkred\", label=\"Target GMM components\")\n",
    "ax.set_xlabel(\"SFL (Side Fluorescence)\")\n",
    "ax.set_ylabel(\"FSC (Forward Scatter)\")\n",
    "ax.set_title(\"Target Data + Target GMM Components + Manual Gates\")\n",
    "ax.set_xlim(0, 260)\n",
    "ax.set_ylim(0, 260)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend(loc=\"upper right\", fontsize=8)\n",
    "\n",
    "# ===== Plot 3: GMM component weight distribution =====\n",
    "ax = axes[1, 0]\n",
    "source_weights = source_gmm.weights_\n",
    "target_weights = target_gmm.weights_\n",
    "x = np.arange(len(source_weights))\n",
    "width = 0.35\n",
    "ax.bar(x - width / 2, source_weights, width, label=\"Source\", alpha=0.7)\n",
    "ax.bar(x + width / 2, target_weights, width, label=\"Target\", alpha=0.7)\n",
    "ax.set_xlabel(\"Component Index\")\n",
    "ax.set_ylabel(\"Weight\")\n",
    "ax.set_title(\"GMM Component Weights (showing collapse to few components)\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3, axis=\"y\")\n",
    "ax.axhline(y=0.01, color=\"r\", linestyle=\"--\", alpha=0.5, label=\"1% threshold\")\n",
    "\n",
    "# ===== Plot 4: Population coverage analysis =====\n",
    "ax = axes[1, 1]\n",
    "\n",
    "\n",
    "# For each gate, count how many GMM components have their mean inside\n",
    "def point_in_polygon(point, polygon):\n",
    "    from matplotlib.path import Path\n",
    "\n",
    "    path = Path(polygon)\n",
    "    return path.contains_point(point)\n",
    "\n",
    "\n",
    "def analyze_gate_coverage(gmm, gates_dict):\n",
    "    coverage = {}\n",
    "    means = gmm.means_\n",
    "    weights = gmm.weights_\n",
    "\n",
    "    for pop_name, coords in gates_dict.items():\n",
    "        if len(coords) == 0:\n",
    "            continue\n",
    "        components_in_gate = []\n",
    "        total_weight_in_gate = 0.0\n",
    "\n",
    "        for i, (mean, weight) in enumerate(zip(means, weights)):\n",
    "            if point_in_polygon(mean, coords):\n",
    "                components_in_gate.append(i)\n",
    "                total_weight_in_gate += weight\n",
    "\n",
    "        coverage[pop_name] = {\n",
    "            \"n_components\": len(components_in_gate),\n",
    "            \"total_weight\": total_weight_in_gate,\n",
    "            \"components\": components_in_gate,\n",
    "        }\n",
    "\n",
    "    return coverage\n",
    "\n",
    "\n",
    "source_coverage = analyze_gate_coverage(source_gmm, gates)\n",
    "target_coverage = analyze_gate_coverage(target_gmm, gates)\n",
    "\n",
    "# Display coverage as text\n",
    "text_str = \"GMM Coverage of Manual Gate Regions:\\n\\n\"\n",
    "text_str += \"SOURCE GMM:\\n\"\n",
    "for pop, data in source_coverage.items():\n",
    "    text_str += f\"  {pop}: {data['n_components']} components, {data['total_weight']:.1%} weight\\n\"\n",
    "\n",
    "text_str += \"\\nTARGET GMM:\\n\"\n",
    "for pop, data in target_coverage.items():\n",
    "    text_str += f\"  {pop}: {data['n_components']} components, {data['total_weight']:.1%} weight\\n\"\n",
    "\n",
    "text_str += (\n",
    "    \"\\nWARNING: If RET/PLT gates have low weight,\\nrare populations are being ignored!\"\n",
    ")\n",
    "\n",
    "ax.text(\n",
    "    0.1,\n",
    "    0.5,\n",
    "    text_str,\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=11,\n",
    "    verticalalignment=\"center\",\n",
    "    family=\"monospace\",\n",
    "    bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.8),\n",
    ")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/gmm_diagnostic.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Diagnostic plot saved to ../outputs/gmm_diagnostic.png\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - Top left: Source data with GMM means (sized by component weight)\")\n",
    "print(\"  - Top right: Target data with GMM means (sized by component weight)\")\n",
    "print(\"  - Bottom left: Component weight distribution (should be spread out)\")\n",
    "print(\"  - Bottom right: How many components cover each gated population\")\n",
    "print(\n",
    "    \"\\nWARNING: If most components cluster in RBC region, rare populations (RET/PLT) are lost!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc258a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGAIN with publication formatting\n",
    "\n",
    "# Load the manually-defined gates for RET channel\n",
    "gate_file = \"../../sysmexcbctools/transfer/flow_gates/json_gates/RET_gates.json\"\n",
    "with open(gate_file, \"r\") as f:\n",
    "    gates = json.load(f)\n",
    "\n",
    "print(\"Available gate populations:\")\n",
    "for pop_name, coords in gates.items():\n",
    "    print(f\"  - {pop_name}: {len(coords)} vertices\")\n",
    "\n",
    "# Get data and GMM fits\n",
    "source_data = transformer.source_data_\n",
    "target_data = transformer.target_data_\n",
    "source_gmm = transformer.source_gmm_\n",
    "target_gmm = transformer.target_gmm_\n",
    "\n",
    "# Downsample for visualization\n",
    "n_plot = min(50000, len(source_data), len(target_data))\n",
    "np.random.seed(42)\n",
    "source_plot_idx = np.random.choice(len(source_data), n_plot, replace=False)\n",
    "target_plot_idx = np.random.choice(len(target_data), n_plot, replace=False)\n",
    "\n",
    "source_plot = source_data[source_plot_idx]\n",
    "target_plot = target_data[target_plot_idx]\n",
    "\n",
    "# Create comprehensive diagnostic figure\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "fig, axes = plt.subplots(1, 2, figsize=(5, 2.5))\n",
    "\n",
    "\n",
    "# Helper function to add gates to plot\n",
    "def add_gates_to_plot(ax, gates_dict, alpha=0.5):\n",
    "    colors = {\"RBC\": \"red\", \"RET\": \"blue\", \"PLT\": \"green\"}\n",
    "    for pop_name, coords in gates_dict.items():\n",
    "        if len(coords) > 0:\n",
    "            poly = Polygon(\n",
    "                coords,\n",
    "                fill=False,\n",
    "                edgecolor=colors.get(pop_name, \"gray\"),\n",
    "                linewidth=2,\n",
    "                alpha=alpha,\n",
    "                label=f\"{pop_name} gate\",\n",
    "            )\n",
    "            ax.add_patch(poly)\n",
    "\n",
    "\n",
    "# Helper function to add GMM components\n",
    "def add_gmm_components(\n",
    "    ax, gmm, color=\"red\", marker=\"x\", size=30, alpha=0.8, label=\"GMM\"\n",
    "):\n",
    "    means = gmm.means_\n",
    "    # Get component weights for sizing\n",
    "    weights = gmm.weights_\n",
    "    sizes = weights * size * 10  # Scale by weights\n",
    "    ax.scatter(\n",
    "        means[:, 0],\n",
    "        means[:, 1],\n",
    "        c=color,\n",
    "        marker=marker,\n",
    "        s=sizes,\n",
    "        alpha=alpha,\n",
    "        edgecolors=\"black\",\n",
    "        linewidths=1,\n",
    "        label=label,\n",
    "        zorder=10,\n",
    "    )\n",
    "\n",
    "    # Add component numbers\n",
    "    # for i, (mean, weight) in enumerate(zip(means, weights)):\n",
    "    #     ax.annotate(f'{i}\\n({weight:.2%})', mean, fontsize=4, ha='center', va='center',\n",
    "    #                bbox=dict(boxstyle='round,pad=0.1', facecolor='white', alpha=0.7, edgecolor=color))\n",
    "\n",
    "\n",
    "# ===== Plot 1: Source data with Source GMM =====\n",
    "# ax = axes[0, 0]\n",
    "ax = axes[0]\n",
    "ax.scatter(\n",
    "    source_plot[:, 0], source_plot[:, 1], s=1, alpha=0.1, c=\"blue\", rasterized=True\n",
    ")\n",
    "# add_gates_to_plot(ax, gates)\n",
    "add_gmm_components(\n",
    "    ax, source_gmm, color=\"red\", label=\"Source GMM\\ncomponents\\n(size $\\propto$ weight)\"\n",
    ")\n",
    "ax.set_xlabel(\"SFL\")\n",
    "ax.set_ylabel(\"FSC\")\n",
    "# ax.set_title('Source Data + Source GMM Components + Manual Gates')\n",
    "ax.set_xlim(0, 260)\n",
    "ax.set_ylim(0, 260)\n",
    "ax.grid(alpha=0.3)\n",
    "lg = ax.legend(loc=\"upper right\", frameon=True, fancybox=False)\n",
    "frame = lg.get_frame()\n",
    "frame.set_edgecolor(\"black\")\n",
    "frame.set_linewidth(1.0)\n",
    "frame.set_alpha(1.0)\n",
    "\n",
    "# ===== Plot 2: Target data with Target GMM =====\n",
    "# ax = axes[0, 1]\n",
    "ax = axes[1]\n",
    "ax.scatter(\n",
    "    target_plot[:, 0], target_plot[:, 1], s=1, alpha=0.1, c=\"orange\", rasterized=True\n",
    ")\n",
    "# add_gates_to_plot(ax, gates)\n",
    "add_gmm_components(\n",
    "    ax,\n",
    "    target_gmm,\n",
    "    color=\"darkred\",\n",
    "    label=\"Target GMM\\ncomponents\\n(size $\\propto$ weight)\",\n",
    ")\n",
    "ax.set_xlabel(\"SFL\")\n",
    "ax.set_ylabel(\"FSC\")\n",
    "# ax.set_title('Target Data + Target GMM Components + Manual Gates')\n",
    "ax.set_xlim(0, 260)\n",
    "ax.set_ylim(0, 260)\n",
    "ax.grid(alpha=0.3)\n",
    "lg = ax.legend(loc=\"upper right\", frameon=True, fancybox=False)\n",
    "frame = lg.get_frame()\n",
    "frame.set_edgecolor(\"black\")\n",
    "frame.set_linewidth(1.0)\n",
    "frame.set_alpha(1.0)\n",
    "\n",
    "# # ===== Plot 3: GMM component weight distribution =====\n",
    "# ax = axes[1, 0]\n",
    "# source_weights = source_gmm.weights_\n",
    "# target_weights = target_gmm.weights_\n",
    "# x = np.arange(len(source_weights))\n",
    "# width = 0.35\n",
    "# ax.bar(x - width/2, source_weights, width, label='Source', alpha=0.7)\n",
    "# ax.bar(x + width/2, target_weights, width, label='Target', alpha=0.7)\n",
    "# ax.set_xlabel('Component Index')\n",
    "# ax.set_ylabel('Weight')\n",
    "# ax.set_title('GMM Component Weights (showing collapse to few components)')\n",
    "# ax.legend()\n",
    "# ax.grid(alpha=0.3, axis='y')\n",
    "# ax.axhline(y=0.01, color='r', linestyle='--', alpha=0.5, label='1% threshold')\n",
    "\n",
    "# # ===== Plot 4: Population coverage analysis =====\n",
    "# ax = axes[1, 1]\n",
    "\n",
    "# # For each gate, count how many GMM components have their mean inside\n",
    "# def point_in_polygon(point, polygon):\n",
    "#     from matplotlib.path import Path\n",
    "#     path = Path(polygon)\n",
    "#     return path.contains_point(point)\n",
    "\n",
    "# def analyze_gate_coverage(gmm, gates_dict):\n",
    "#     coverage = {}\n",
    "#     means = gmm.means_\n",
    "#     weights = gmm.weights_\n",
    "\n",
    "#     for pop_name, coords in gates_dict.items():\n",
    "#         if len(coords) == 0:\n",
    "#             continue\n",
    "#         components_in_gate = []\n",
    "#         total_weight_in_gate = 0.0\n",
    "\n",
    "#         for i, (mean, weight) in enumerate(zip(means, weights)):\n",
    "#             if point_in_polygon(mean, coords):\n",
    "#                 components_in_gate.append(i)\n",
    "#                 total_weight_in_gate += weight\n",
    "\n",
    "#         coverage[pop_name] = {\n",
    "#             'n_components': len(components_in_gate),\n",
    "#             'total_weight': total_weight_in_gate,\n",
    "#             'components': components_in_gate\n",
    "#         }\n",
    "\n",
    "#     return coverage\n",
    "\n",
    "# source_coverage = analyze_gate_coverage(source_gmm, gates)\n",
    "# target_coverage = analyze_gate_coverage(target_gmm, gates)\n",
    "\n",
    "# # Display coverage as text\n",
    "# text_str = \"GMM Coverage of Manual Gate Regions:\\n\\n\"\n",
    "# text_str += \"SOURCE GMM:\\n\"\n",
    "# for pop, data in source_coverage.items():\n",
    "#     text_str += f\"  {pop}: {data['n_components']} components, {data['total_weight']:.1%} weight\\n\"\n",
    "\n",
    "# text_str += \"\\nTARGET GMM:\\n\"\n",
    "# for pop, data in target_coverage.items():\n",
    "#     text_str += f\"  {pop}: {data['n_components']} components, {data['total_weight']:.1%} weight\\n\"\n",
    "\n",
    "# text_str += \"\\n⚠️ Problem: If RET/PLT gates have low weight,\\nrare populations are being ignored!\"\n",
    "\n",
    "# ax.text(0.1, 0.5, text_str, transform=ax.transAxes, fontsize=11,\n",
    "#         verticalalignment='center', family='monospace',\n",
    "#         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "# ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/gmm_diagnostic.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.savefig(\"../outputs/gmm_diagnostic.pdf\", dpi=400, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Diagnostic plot saved to ../outputs/gmm_diagnostic.png\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - Top left: Source data with GMM means (sized by component weight)\")\n",
    "print(\"  - Top right: Target data with GMM means (sized by component weight)\")\n",
    "print(\"  - Bottom left: Component weight distribution (should be spread out)\")\n",
    "print(\"  - Bottom right: How many components cover each gated population\")\n",
    "print(\n",
    "    \"\\nWARNING If most components cluster in RBC region, rare populations (RET/PLT) are lost!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Working with Different Channels\n",
    "\n",
    "The same workflow applies to other flow cytometry channels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bloodcounts_sysmex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
